{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-26T00:33:29.623365Z",
          "iopub.status.busy": "2026-01-26T00:33:29.622785Z",
          "iopub.status.idle": "2026-01-26T00:33:29.757233Z",
          "shell.execute_reply": "2026-01-26T00:33:29.756472Z",
          "shell.execute_reply.started": "2026-01-26T00:33:29.623329Z"
        },
        "id": "lGnPHrACa8FR",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import warnings\n",
        "import time\n",
        "import os\n",
        "\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, jaccard_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from datasets import Dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer\n",
        ")\n",
        "from tqdm import tqdm\n",
        "import gc\n",
        "\n",
        "from codecarbon import EmissionsTracker\n",
        "from dataclasses import dataclass\n",
        "from typing import Any, Dict, List"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-26T00:33:31.869200Z",
          "iopub.status.busy": "2026-01-26T00:33:31.868430Z",
          "iopub.status.idle": "2026-01-26T00:33:31.872503Z",
          "shell.execute_reply": "2026-01-26T00:33:31.871943Z",
          "shell.execute_reply.started": "2026-01-26T00:33:31.869168Z"
        },
        "trusted": true,
        "id": "HaABnzufv4d-"
      },
      "outputs": [],
      "source": [
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-26T00:33:32.786993Z",
          "iopub.status.busy": "2026-01-26T00:33:32.786260Z",
          "iopub.status.idle": "2026-01-26T00:33:32.791536Z",
          "shell.execute_reply": "2026-01-26T00:33:32.790790Z",
          "shell.execute_reply.started": "2026-01-26T00:33:32.786963Z"
        },
        "trusted": true,
        "id": "hWkwqARXv4d_",
        "outputId": "63688107-5462-4c2e-d7f5-25184461261e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ PyTorch: 2.5.1+cu121\n",
            "‚úÖ CUDA: True\n",
            "‚úÖ Device: cuda\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(f\"‚úÖ PyTorch: {torch.__version__}\")\n",
        "print(f\"‚úÖ CUDA: {torch.cuda.is_available()}\")\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"‚úÖ Device: {device}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-26T00:43:54.942271Z",
          "iopub.status.busy": "2026-01-26T00:43:54.941649Z",
          "iopub.status.idle": "2026-01-26T00:43:57.715719Z",
          "shell.execute_reply": "2026-01-26T00:43:57.714932Z",
          "shell.execute_reply.started": "2026-01-26T00:43:54.942245Z"
        },
        "trusted": true,
        "id": "lt1ReTr_v4d_",
        "outputId": "98839936-b978-4992-a362-3ac7b9c64bbf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìÇ Loading data...\n",
            "üßπ Preprocessing...\n",
            "Pruning rule: keep samples with ‚â§ 20 labels\n",
            "Before: 6240 | Removed: 16 (0.26%) | After: 6224\n",
            "Labels/sample (after) - mean: 3.965\n",
            "Labels/sample (after) - max: 33\n",
            "   Samples: 6224\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ======================\n",
        "# LOAD DATA\n",
        "# ======================\n",
        "print(\"üìÇ Loading data...\")\n",
        "df = pd.read_excel(\"dataset.xlsx\")\n",
        "df = df.dropna(subset=[\"text_raw\"]).rename(columns={\"text_raw\": \"text\"})\n",
        "\n",
        "# ======================\n",
        "# PREPROCESSING\n",
        "# ======================\n",
        "def advanced_clean(text):\n",
        "    if pd.isna(text): return \"\"\n",
        "    text = str(text)\n",
        "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
        "    text = re.sub(r'\\S+@\\S+', '', text)\n",
        "    text = re.sub(r'<.*?>', '', text)\n",
        "    text = re.sub(r'[^\\w\\s\\-\\.\\,\\!\\?\\%]', ' ', text)\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    text = text.lower().strip()\n",
        "    if len(text.split()) < 3: return \"\"\n",
        "    return text\n",
        "\n",
        "\n",
        "LABEL_COLUMNS = [\n",
        "    \"acne\", \"eye_contour\", \"homogeneity\", \"lack_firmness\", \"lack_radiance\",\n",
        "    \"pores\", \"fine_lines\", \"wrinkles_fine-lines\", \"eye-wrinkles\", \"undereye-bags\",\n",
        "    \"generic\", \"18-34\", \"35-54\", \"55-99\", \"dark_pigmentation\", \"dry\", \"normal\",\n",
        "    \"oily\", \"combination\", \"sensitivity-high\", \"sensitivity-low\", \"no_sensitivity\",\n",
        "    \"male\", \"female\", \"cleanse\", \"prepare\", \"treat\", \"targeted\", \"care\",\n",
        "    \"moisturize\", \"protect\", \"day\", \"night\"\n",
        "]\n",
        "\n",
        "print(\"üßπ Preprocessing...\")\n",
        "\n",
        "# ======================\n",
        "# DATA PRUNING\n",
        "# ======================\n",
        "MAX_LABELS_PER_SAMPLE = 20  # more than 60% of labels\n",
        "\n",
        "# Ensure labels are numeric and NaNs are treated as 0\n",
        "label_matrix = df[LABEL_COLUMNS].fillna(0).astype(int)\n",
        "\n",
        "# Count active labels per sample\n",
        "labels_per_sample = label_matrix.sum(axis=1)\n",
        "\n",
        "before_n = len(df)\n",
        "removed_mask = labels_per_sample > MAX_LABELS_PER_SAMPLE\n",
        "removed_n = int(removed_mask.sum())\n",
        "removed_pct = (100.0 * removed_n / before_n) if before_n > 0 else 0.0\n",
        "\n",
        "# Prune\n",
        "df = df.loc[~removed_mask].copy().reset_index(drop=True)\n",
        "label_matrix = label_matrix.loc[df.index]\n",
        "\n",
        "print(f\"Pruning rule: keep samples with ‚â§ {MAX_LABELS_PER_SAMPLE} labels\")\n",
        "print(f\"Before: {before_n} | Removed: {removed_n} ({removed_pct:.2f}%) | After: {len(df)}\")\n",
        "print(\"Labels/sample (after) - mean:\", round(label_matrix.sum(axis=1).mean(), 3))\n",
        "print(\"Labels/sample (after) - max:\", int(label_matrix.sum(axis=1).max()))\n",
        "\n",
        "df[\"cleaned_text\"] = df[\"text\"].apply(advanced_clean)\n",
        "df = df[df[\"cleaned_text\"].str.len() > 0]\n",
        "df[\"labels\"] = df[LABEL_COLUMNS].apply(lambda row: row.tolist(), axis=1)\n",
        "print(f\"   Samples: {len(df)}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-26T00:44:00.800480Z",
          "iopub.status.busy": "2026-01-26T00:44:00.799807Z",
          "iopub.status.idle": "2026-01-26T00:44:00.823617Z",
          "shell.execute_reply": "2026-01-26T00:44:00.822922Z",
          "shell.execute_reply.started": "2026-01-26T00:44:00.800453Z"
        },
        "trusted": true,
        "id": "BQMDE-dfv4eA",
        "outputId": "77c4d9be-73f9-4047-fb15-f047a58c5a85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîÑ Oversampling rare age & gender labels...\n",
            "\n",
            "Before oversampling:\n",
            "18-34     182\n",
            "35-54     800\n",
            "55-99     262\n",
            "male      335\n",
            "female    113\n",
            "dtype: int64\n",
            "\n",
            "Oversampling factors: {'18-34': 2, '35-54': 0, '55-99': 1, 'male': 1, 'female': 4}\n",
            "   18-34: 182 ‚Üí 364\n",
            "   female: 113 ‚Üí 452\n",
            "\n",
            "Dataset size: 6224 ‚Üí 6745 (+521)\n",
            "\n",
            "After oversampling:\n",
            "18-34      430\n",
            "35-54     1038\n",
            "55-99      424\n",
            "male       350\n",
            "female     474\n",
            "dtype: int64\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ======================\n",
        "# OVERSAMPLE RARE AGE & GENDER LABELS\n",
        "# ======================\n",
        "print(\"üîÑ Oversampling rare age & gender labels...\")\n",
        "\n",
        "# Define age and gender labels\n",
        "AGE_LABELS = [\"18-34\", \"35-54\", \"55-99\"]\n",
        "GENDER_LABELS = [\"male\", \"female\"]\n",
        "RARE_LABELS = AGE_LABELS + GENDER_LABELS\n",
        "\n",
        "# Calculate support for each label\n",
        "label_counts = df[RARE_LABELS].sum()\n",
        "print(\"\\nBefore oversampling:\")\n",
        "print(label_counts)\n",
        "\n",
        "# Define oversampling strategy\n",
        "TARGET_MIN_SAMPLES = 500  # Target minimum samples per label\n",
        "oversample_factor = {}\n",
        "\n",
        "for label in RARE_LABELS:\n",
        "    count = label_counts[label]\n",
        "    if count < TARGET_MIN_SAMPLES and count > 0:\n",
        "        oversample_factor[label] = int(TARGET_MIN_SAMPLES / count)\n",
        "    else:\n",
        "        oversample_factor[label] = 0\n",
        "\n",
        "print(f\"\\nOversampling factors: {oversample_factor}\")\n",
        "\n",
        "# Perform oversampling\n",
        "df_original = df.copy()\n",
        "samples_to_add = []\n",
        "\n",
        "for label, factor in oversample_factor.items():\n",
        "    if factor > 1:\n",
        "        # Get samples with this label\n",
        "        label_samples = df[df[label] == 1]\n",
        "\n",
        "        # Replicate (factor - 1) times (we already have original)\n",
        "        for _ in range(factor - 1):\n",
        "            samples_to_add.append(label_samples)\n",
        "\n",
        "        print(f\"   {label}: {len(label_samples)} ‚Üí {len(label_samples) * factor}\")\n",
        "\n",
        "# Concatenate all samples\n",
        "if samples_to_add:\n",
        "    df = pd.concat([df] + samples_to_add, ignore_index=True)\n",
        "\n",
        "    # Shuffle to avoid clustering\n",
        "    df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "print(f\"\\nDataset size: {len(df_original)} ‚Üí {len(df)} (+{len(df) - len(df_original)})\")\n",
        "print(\"\\nAfter oversampling:\")\n",
        "print(df[RARE_LABELS].sum())\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-26T00:44:05.559664Z",
          "iopub.status.busy": "2026-01-26T00:44:05.559273Z",
          "iopub.status.idle": "2026-01-26T00:44:05.570030Z",
          "shell.execute_reply": "2026-01-26T00:44:05.569382Z",
          "shell.execute_reply.started": "2026-01-26T00:44:05.559631Z"
        },
        "trusted": true,
        "id": "KY87jvqgv4eA",
        "outputId": "129b8605-c45c-4b27-b819-3fda2f0fec11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚öñÔ∏è  Weights: 1.60 - 12.00\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ======================\n",
        "# CLASS WEIGHTS\n",
        "# ======================\n",
        "y = np.array(df[LABEL_COLUMNS].values, dtype=np.float32)\n",
        "pos = y.sum(axis=0)\n",
        "weights = []\n",
        "for i in range(len(LABEL_COLUMNS)):\n",
        "    if pos[i] < 50: w = min(20.0, (len(df) - pos[i]) / (pos[i] + 1))  # Increased from 15\n",
        "    elif pos[i] < 100: w = min(12.0, (len(df) - pos[i]) / (pos[i] + 1))  # NEW bracket\n",
        "    elif pos[i] < 200: w = min(8.0, (len(df) - pos[i]) / (pos[i] + 1))\n",
        "    else: w = min(3.0, (len(df) - pos[i]) / (pos[i] + 1))\n",
        "    weights.append(w)\n",
        "\n",
        "class_weights = torch.tensor(weights, dtype=torch.float32).to(device)\n",
        "print(f\"‚öñÔ∏è  Weights: {min(weights):.2f} - {max(weights):.2f}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-26T00:44:08.701413Z",
          "iopub.status.busy": "2026-01-26T00:44:08.700632Z",
          "iopub.status.idle": "2026-01-26T00:44:08.796324Z",
          "shell.execute_reply": "2026-01-26T00:44:08.795572Z",
          "shell.execute_reply.started": "2026-01-26T00:44:08.701382Z"
        },
        "trusted": true,
        "id": "QLpmGbKUv4eA",
        "outputId": "4f1fadfb-70b2-43ab-8068-774e6ef2c1e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÇÔ∏è  Train: 5396 | Test: 1349\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ======================\n",
        "# SPLIT\n",
        "# ======================\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df[LABEL_COLUMNS[0]])\n",
        "print(f\"‚úÇÔ∏è  Train: {len(train_df)} | Test: {len(test_df)}\\n\")\n",
        "\n",
        "train_ds = Dataset.from_pandas(train_df[[\"cleaned_text\", \"labels\"]].reset_index(drop=True))\n",
        "test_ds = Dataset.from_pandas(test_df[[\"cleaned_text\", \"labels\"]].reset_index(drop=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-26T00:44:32.244082Z",
          "iopub.status.busy": "2026-01-26T00:44:32.243456Z",
          "iopub.status.idle": "2026-01-26T00:44:36.626706Z",
          "shell.execute_reply": "2026-01-26T00:44:36.625916Z",
          "shell.execute_reply.started": "2026-01-26T00:44:32.244038Z"
        },
        "trusted": true,
        "id": "VJ40HCLxv4eB"
      },
      "outputs": [],
      "source": [
        "# ======================\n",
        "# DEFINE EMISSIONS TRACKER\n",
        "# ======================\n",
        "os.makedirs(\"/kaggle/working/EmissionsTracker\", exist_ok=True)\n",
        "\n",
        "tracker = EmissionsTracker(\n",
        "    project_name=\"roberta_large_eval\",\n",
        "    output_dir=\"/kaggle/working/EmissionsTracker\",\n",
        "    log_level=\"error\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-26T00:44:43.190564Z",
          "iopub.status.busy": "2026-01-26T00:44:43.189795Z",
          "iopub.status.idle": "2026-01-26T00:44:43.194006Z",
          "shell.execute_reply": "2026-01-26T00:44:43.193386Z",
          "shell.execute_reply.started": "2026-01-26T00:44:43.190535Z"
        },
        "trusted": true,
        "id": "a70ht1gnv4eB"
      },
      "outputs": [],
      "source": [
        "# ======================\n",
        "# TEACHER MODEL CONFIGURATION\n",
        "# ======================\n",
        "MODEL_NAME = \"roberta-large\"\n",
        "MAX_LENGTH = 256\n",
        "BATCH_SIZE = 4\n",
        "GRAD_ACCUM = 8\n",
        "EPOCHS = 25\n",
        "LEARNING_RATE = 3e-5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-26T00:44:51.315668Z",
          "iopub.status.busy": "2026-01-26T00:44:51.314896Z",
          "iopub.status.idle": "2026-01-26T00:44:52.614640Z",
          "shell.execute_reply": "2026-01-26T00:44:52.613855Z",
          "shell.execute_reply.started": "2026-01-26T00:44:51.315637Z"
        },
        "trusted": true,
        "id": "uZ-mXO7Tv4eB",
        "outputId": "d7fb1196-bfa1-40d2-88a2-8c0c1907c935"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading model from models/RoBERTa_final...\n",
            "‚úÖ Model and Tokenizer loaded successfully!\n"
          ]
        }
      ],
      "source": [
        "# 1. Path to the folder containing your uploaded files\n",
        "#    (e.g., if you uploaded them to a folder named 'roberta_skin_model')\n",
        "MODEL_PATH = \"models/RoBERTa_final\"\n",
        "\n",
        "print(f\"Loading model from {MODEL_PATH}...\")\n",
        "\n",
        "# 2. Load the Tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
        "\n",
        "# 3. Load the Model\n",
        "#    Note: We don't need to specify num_labels here; it reads it from config.json\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    MODEL_PATH,\n",
        "    use_safetensors=True  # Set to False if you only have 'pytorch_model.bin'\n",
        ")\n",
        "\n",
        "# 4. Move to GPU if available\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device)\n",
        "model.eval() # Set to evaluation mode\n",
        "\n",
        "print(\"‚úÖ Model and Tokenizer loaded successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-26T00:44:56.573715Z",
          "iopub.status.busy": "2026-01-26T00:44:56.573427Z",
          "iopub.status.idle": "2026-01-26T00:44:56.580751Z",
          "shell.execute_reply": "2026-01-26T00:44:56.580017Z",
          "shell.execute_reply.started": "2026-01-26T00:44:56.573689Z"
        },
        "trusted": true,
        "id": "gytq_0duv4eB",
        "outputId": "7dffc03d-b651-465f-c266-e2f78d5e6c2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚ùÑÔ∏è Teacher model frozen and ready for distillation.\n"
          ]
        }
      ],
      "source": [
        "# Assuming 'model' is your loaded Teacher (RoBERTa)\n",
        "model.eval()\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "print(\"‚ùÑÔ∏è Teacher model frozen and ready for distillation.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-26T00:45:00.419312Z",
          "iopub.status.busy": "2026-01-26T00:45:00.418657Z",
          "iopub.status.idle": "2026-01-26T00:46:22.379399Z",
          "shell.execute_reply": "2026-01-26T00:46:22.378740Z",
          "shell.execute_reply.started": "2026-01-26T00:45:00.419284Z"
        },
        "trusted": true,
        "id": "OGpnxlmTv4eB",
        "outputId": "995d50c2-9b89-4b74-e6fb-db77fc4a9525"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîÆ Generating Teacher Logits for Training Data...\n",
            "‚úÖ Logits Ready. Train shape: torch.Size([5396, 33])\n"
          ]
        }
      ],
      "source": [
        "# Helper function to generate logits in batches (to avoid OOM errors)\n",
        "def generate_logits(model, tokenizer, texts, batch_size=32, device='cuda'):\n",
        "    model.to(device)\n",
        "    all_logits = []\n",
        "\n",
        "    # Simple batching loop\n",
        "    for i in range(0, len(texts), batch_size):\n",
        "        batch_texts = texts[i : i + batch_size]\n",
        "\n",
        "        # Tokenize (Use the TEACHER'S tokenizer here!)\n",
        "        inputs = tokenizer(\n",
        "            batch_texts,\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=128,\n",
        "            return_tensors=\"pt\"\n",
        "        ).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "            all_logits.append(outputs.logits.cpu()) # Move to CPU immediately to save GPU\n",
        "\n",
        "    return torch.cat(all_logits)\n",
        "\n",
        "print(\"üîÆ Generating Teacher Logits for Training Data...\")\n",
        "# Get the raw text list from your dataframe\n",
        "train_texts = train_df['cleaned_text'].tolist()\n",
        "test_texts = test_df['cleaned_text'].tolist()\n",
        "\n",
        "# Generate\n",
        "teacher_train_logits = generate_logits(model, tokenizer, train_texts)\n",
        "teacher_test_logits = generate_logits(model, tokenizer, test_texts)\n",
        "\n",
        "print(f\"‚úÖ Logits Ready. Train shape: {teacher_train_logits.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-26T00:48:01.973229Z",
          "iopub.status.busy": "2026-01-26T00:48:01.972479Z",
          "iopub.status.idle": "2026-01-26T00:48:02.443380Z",
          "shell.execute_reply": "2026-01-26T00:48:02.442660Z",
          "shell.execute_reply.started": "2026-01-26T00:48:01.973200Z"
        },
        "trusted": true,
        "id": "siB6fIVWv4eC",
        "outputId": "06d03c9e-6a14-4bb2-ac2c-a6784a8ca6de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üóëÔ∏è Teacher model removed from GPU to make room for the Student.\n"
          ]
        }
      ],
      "source": [
        "# Delete the teacher model to free up VRAM\n",
        "del model\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "print(\"üóëÔ∏è Teacher model removed from GPU to make room for the Student.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-26T00:48:07.353945Z",
          "iopub.status.busy": "2026-01-26T00:48:07.353610Z",
          "iopub.status.idle": "2026-01-26T00:48:07.359393Z",
          "shell.execute_reply": "2026-01-26T00:48:07.358555Z",
          "shell.execute_reply.started": "2026-01-26T00:48:07.353918Z"
        },
        "trusted": true,
        "id": "sc_-pVOjv4eC",
        "outputId": "9154af50-2921-4ba7-b7ab-6412b9689108"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "üéì KNOWLEDGE DISTILLATION - SUSTAINABILITY-OPTIMIZED\n",
            "================================================================================\n",
            "\n",
            "üìö Teacher: roberta-large\n",
            "üéì Student: distilroberta-base\n",
            "üìè Student max length: 128\n",
            "üî• Temperature: 3.0\n",
            "‚öñÔ∏è  Alpha (KD weight): 0.9\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ======================================================================================\n",
        "# üéì KNOWLEDGE DISTILLATION: ROBERTA-LARGE ‚Üí DISTILROBERTA\n",
        "# ======================================================================================\n",
        "print(\"=\"*80)\n",
        "print(\"üéì KNOWLEDGE DISTILLATION - SUSTAINABILITY-OPTIMIZED\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# ======================\n",
        "# STUDENT MODEL SETUP\n",
        "# ======================\n",
        "STUDENT_MODEL_NAME = \"distilroberta-base\"\n",
        "STUDENT_MAX_LENGTH = 128\n",
        "STUDENT_EPOCHS = 20\n",
        "STUDENT_BATCH_SIZE = 16\n",
        "STUDENT_GRAD_ACCUM = 4\n",
        "STUDENT_LR = 4e-5\n",
        "TEMPERATURE = 3.0\n",
        "DISTILLATION_ALPHA = 0.9\n",
        "\n",
        "\n",
        "print(f\"\\nüìö Teacher: {MODEL_NAME}\")\n",
        "print(f\"üéì Student: {STUDENT_MODEL_NAME}\")\n",
        "print(f\"üìè Student max length: {STUDENT_MAX_LENGTH}\")\n",
        "print(f\"üî• Temperature: {TEMPERATURE}\")\n",
        "print(f\"‚öñÔ∏è  Alpha (KD weight): {DISTILLATION_ALPHA}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-26T00:49:15.601917Z",
          "iopub.status.busy": "2026-01-26T00:49:15.601599Z",
          "iopub.status.idle": "2026-01-26T00:49:15.616815Z",
          "shell.execute_reply": "2026-01-26T00:49:15.616016Z",
          "shell.execute_reply.started": "2026-01-26T00:49:15.601893Z"
        },
        "trusted": true,
        "id": "M4GwoBILv4eC",
        "outputId": "fb1094ee-2c99-40dc-8ac5-c67254826353"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚öôÔ∏è formatting labels column...\n",
            "‚úÖ 'labels' column created successfully.\n"
          ]
        }
      ],
      "source": [
        "# ======================\n",
        "# STEP 1: FORMATTING LABELS COLUMN\n",
        "# ======================\n",
        "print(\"‚öôÔ∏è formatting labels column...\")\n",
        "\n",
        "train_df['labels'] = train_df[LABEL_COLUMNS].values.tolist()\n",
        "test_df['labels'] = test_df[LABEL_COLUMNS].values.tolist()\n",
        "\n",
        "print(\"‚úÖ 'labels' column created successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-26T00:49:19.685690Z",
          "iopub.status.busy": "2026-01-26T00:49:19.685381Z",
          "iopub.status.idle": "2026-01-26T00:49:19.811780Z",
          "shell.execute_reply": "2026-01-26T00:49:19.811137Z",
          "shell.execute_reply.started": "2026-01-26T00:49:19.685665Z"
        },
        "trusted": true,
        "id": "exXYpVQAv4eC",
        "outputId": "d1f00deb-9338-4dcf-d734-38d47617b197"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "STEP 2: Creating student datasets\n",
            "================================================================================\n",
            "‚úÖ Student datasets created:\n",
            "   Train: 5396\n",
            "   Test: 1349\n",
            "   Train columns: ['cleaned_text', 'labels', 'teacher_logits']\n",
            "\n",
            "‚úÖ Sample verification:\n",
            "   Text type: <class 'str'>\n",
            "   Labels type: <class 'list'>, len: 33\n",
            "   Teacher logits type: <class 'list'>, len: 33\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ======================\n",
        "# STEP 2: CREATE STUDENT DATASETS (DICT-BASED)\n",
        "# ======================\n",
        "print(\"=\"*80)\n",
        "print(\"STEP 2: Creating student datasets\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Create datasets as dictionaries for better compatibility\n",
        "train_data_dict = {\n",
        "    \"cleaned_text\": train_df[\"cleaned_text\"].reset_index(drop=True).tolist(),\n",
        "    \"labels\": train_df[\"labels\"].reset_index(drop=True).tolist(),\n",
        "    \"teacher_logits\": teacher_train_logits.tolist()\n",
        "}\n",
        "\n",
        "test_data_dict = {\n",
        "    \"cleaned_text\": test_df[\"cleaned_text\"].reset_index(drop=True).tolist(),\n",
        "    \"labels\": test_df[\"labels\"].reset_index(drop=True).tolist(),\n",
        "    \"teacher_logits\": teacher_test_logits.tolist()\n",
        "}\n",
        "\n",
        "# Create HuggingFace datasets from dictionaries\n",
        "train_ds_student = Dataset.from_dict(train_data_dict)\n",
        "test_ds_student = Dataset.from_dict(test_data_dict)\n",
        "\n",
        "print(f\"‚úÖ Student datasets created:\")\n",
        "print(f\"   Train: {len(train_ds_student)}\")\n",
        "print(f\"   Test: {len(test_ds_student)}\")\n",
        "print(f\"   Train columns: {train_ds_student.column_names}\")\n",
        "\n",
        "# Verify data structure\n",
        "print(f\"\\n‚úÖ Sample verification:\")\n",
        "sample = train_ds_student[0]\n",
        "print(f\"   Text type: {type(sample['cleaned_text'])}\")\n",
        "print(f\"   Labels type: {type(sample['labels'])}, len: {len(sample['labels'])}\")\n",
        "print(f\"   Teacher logits type: {type(sample['teacher_logits'])}, len: {len(sample['teacher_logits'])}\")\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-26T00:49:23.717872Z",
          "iopub.status.busy": "2026-01-26T00:49:23.717180Z",
          "iopub.status.idle": "2026-01-26T00:49:24.601399Z",
          "shell.execute_reply": "2026-01-26T00:49:24.600768Z",
          "shell.execute_reply.started": "2026-01-26T00:49:23.717830Z"
        },
        "trusted": true,
        "id": "b3L6ZuWbv4eC",
        "outputId": "cd7b62c8-b91a-41ce-dd94-7775ae3a4766"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "STEP 3: Creating custom data collator\n",
            "================================================================================\n",
            "‚úÖ Data collator created\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ======================\n",
        "# STEP 3: CREATE CUSTOM DATA COLLATOR\n",
        "# ======================\n",
        "print(\"=\"*80)\n",
        "print(\"STEP 3: Creating custom data collator\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "student_tokenizer = AutoTokenizer.from_pretrained(STUDENT_MODEL_NAME)\n",
        "\n",
        "# Create a custom collator that handles teacher_logits\n",
        "\n",
        "@dataclass\n",
        "class DistillationDataCollator:\n",
        "    tokenizer: Any\n",
        "    max_length: int = 128\n",
        "\n",
        "    def __call__(self, features: List[Dict[str, Any]]) -> Dict[str, Any]:\n",
        "        # Extract teacher logits and labels (they're already lists/arrays in the dataset)\n",
        "        teacher_logits = torch.tensor(\n",
        "            [f[\"teacher_logits\"] for f in features],\n",
        "            dtype=torch.float32\n",
        "        )\n",
        "        labels = torch.tensor(\n",
        "            [f[\"labels\"] for f in features],\n",
        "            dtype=torch.float32\n",
        "        )\n",
        "\n",
        "        # Extract texts\n",
        "        texts = [f[\"cleaned_text\"] for f in features]\n",
        "\n",
        "        # Tokenize\n",
        "        batch = self.tokenizer(\n",
        "            texts,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            max_length=self.max_length,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        # Add teacher logits and labels to batch\n",
        "        batch[\"teacher_logits\"] = teacher_logits\n",
        "        batch[\"labels\"] = labels\n",
        "\n",
        "        return batch\n",
        "\n",
        "data_collator = DistillationDataCollator(\n",
        "    tokenizer=student_tokenizer,\n",
        "    max_length=STUDENT_MAX_LENGTH\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Data collator created\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-26T00:49:29.709255Z",
          "iopub.status.busy": "2026-01-26T00:49:29.708652Z",
          "iopub.status.idle": "2026-01-26T00:49:29.717216Z",
          "shell.execute_reply": "2026-01-26T00:49:29.716605Z",
          "shell.execute_reply.started": "2026-01-26T00:49:29.709229Z"
        },
        "trusted": true,
        "id": "osgb2UMqv4eC",
        "outputId": "d45e6ab7-c0f7-47f6-b4e5-f06cb93e477c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "STEP 4: Defining distillation loss\n",
            "================================================================================\n",
            "‚úÖ Distillation loss defined\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ======================\n",
        "# STEP 4: DISTILLATION LOSS & TRAINER\n",
        "# ======================\n",
        "print(\"=\"*80)\n",
        "print(\"STEP 4: Defining distillation loss\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "class DistillationLoss(nn.Module):\n",
        "    def __init__(self, alpha=0.7, temperature=2.0, pos_weight=None):\n",
        "        super().__init__()\n",
        "        self.alpha = alpha\n",
        "        self.temperature = temperature\n",
        "        self.pos_weight = pos_weight\n",
        "\n",
        "    def forward(self, student_logits, teacher_logits, labels):\n",
        "        # Knowledge Distillation Loss (MSE on soft targets)\n",
        "        kd_loss = nn.functional.mse_loss(\n",
        "            student_logits / self.temperature,\n",
        "            teacher_logits / self.temperature\n",
        "        )\n",
        "\n",
        "        # Supervised Loss (BCE on hard labels)\n",
        "        bce_loss = nn.functional.binary_cross_entropy_with_logits(\n",
        "            student_logits,\n",
        "            labels,\n",
        "            pos_weight=self.pos_weight\n",
        "        )\n",
        "\n",
        "        # Combined loss\n",
        "        total_loss = self.alpha * kd_loss + (1 - self.alpha) * bce_loss\n",
        "        return total_loss\n",
        "\n",
        "class DistillationTrainer(Trainer):\n",
        "    def __init__(self, *args, distillation_loss_fn=None, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.distillation_loss_fn = distillation_loss_fn\n",
        "\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
        "        labels = inputs.pop(\"labels\").float()\n",
        "        teacher_logits = inputs.pop(\"teacher_logits\").float()\n",
        "\n",
        "        outputs = model(**inputs)\n",
        "        student_logits = outputs.logits\n",
        "\n",
        "        loss = self.distillation_loss_fn(student_logits, teacher_logits, labels)\n",
        "\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "print(\"‚úÖ Distillation loss defined\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-26T00:51:12.144505Z",
          "iopub.status.busy": "2026-01-26T00:51:12.144205Z",
          "iopub.status.idle": "2026-01-26T00:51:12.314653Z",
          "shell.execute_reply": "2026-01-26T00:51:12.313926Z",
          "shell.execute_reply.started": "2026-01-26T00:51:12.144480Z"
        },
        "trusted": true,
        "id": "dXrbmsiwv4eD",
        "outputId": "8fd879c0-6c73-45c4-c03c-7c2808964744"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "STEP 5: Loading student model\n",
            "================================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üë®‚Äçüè´ Teacher parameters: 355,393,569\n",
            "üéì Student parameters: 82,143,777\n",
            "üìâ Compression: 76.9% size reduction\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ======================\n",
        "# STEP 5: LOAD STUDENT MODEL\n",
        "# ======================\n",
        "print(\"=\"*80)\n",
        "print(\"STEP 5: Loading student model\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "student_model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    STUDENT_MODEL_NAME,\n",
        "    num_labels=33,\n",
        "    problem_type=\"multi_label_classification\",\n",
        "    ignore_mismatched_sizes=True\n",
        ")\n",
        "\n",
        "teacher_params = 355393569\n",
        "student_params = sum(p.numel() for p in student_model.parameters())\n",
        "compression_ratio = (1 - student_params / teacher_params) * 100\n",
        "\n",
        "print(f\"üë®‚Äçüè´ Teacher parameters: {teacher_params:,}\")\n",
        "print(f\"üéì Student parameters: {student_params:,}\")\n",
        "print(f\"üìâ Compression: {compression_ratio:.1f}% size reduction\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-26T00:51:16.997650Z",
          "iopub.status.busy": "2026-01-26T00:51:16.996904Z",
          "iopub.status.idle": "2026-01-26T00:51:17.027695Z",
          "shell.execute_reply": "2026-01-26T00:51:17.026915Z",
          "shell.execute_reply.started": "2026-01-26T00:51:16.997621Z"
        },
        "trusted": true,
        "id": "6lV1GE9vv4eD",
        "outputId": "0b2b35e4-56a9-4508-9d4c-a0ef4c7ad229"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "STEP 6: Configuring student training\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# ======================\n",
        "# STEP 6: TRAINING CONFIGURATION\n",
        "# ======================\n",
        "print(\"=\"*80)\n",
        "print(\"STEP 6: Configuring student training\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "distillation_loss_fn = DistillationLoss(\n",
        "    alpha=DISTILLATION_ALPHA,\n",
        "    temperature=TEMPERATURE,\n",
        "    pos_weight=class_weights\n",
        ")\n",
        "\n",
        "student_args = TrainingArguments(\n",
        "    output_dir=\"./DistilRoBERTa_distilled\",\n",
        "\n",
        "    # --- CRITICAL CHANGES FOR LEARNING RATE ---\n",
        "    learning_rate=4e-5,          # Student needs to learn faster\n",
        "    num_train_epochs=20,         # Increased from 5 (Distillation needs time to converge)\n",
        "    warmup_ratio=0.1,            # Standard warm-up\n",
        "    # ------------------------------------------\n",
        "\n",
        "    per_device_train_batch_size=STUDENT_BATCH_SIZE, # Keep at 16 or 32\n",
        "    gradient_accumulation_steps=STUDENT_GRAD_ACCUM,\n",
        "\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    weight_decay=0.01,\n",
        "    max_grad_norm=1.0,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1_macro\",\n",
        "    greater_is_better=True,\n",
        "    logging_steps=50,\n",
        "    save_total_limit=1,\n",
        "    fp16=True,\n",
        "    report_to=\"none\",\n",
        "    seed=42,\n",
        "    remove_unused_columns=False,\n",
        "    lr_scheduler_type=\"cosine\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-26T00:51:51.596443Z",
          "iopub.status.busy": "2026-01-26T00:51:51.595747Z",
          "iopub.status.idle": "2026-01-26T01:01:22.868550Z",
          "shell.execute_reply": "2026-01-26T01:01:22.867919Z",
          "shell.execute_reply.started": "2026-01-26T00:51:51.596416Z"
        },
        "trusted": true,
        "id": "NgfEQag9v4eD",
        "outputId": "ab791d3b-fa69-46f4-ba81-24f27573b1d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "STEP 7: Training student model (TRACKED)\n",
            "================================================================================\n",
            "üöÄ Starting student training with emission tracking...\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1700' max='1700' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1700/1700 10:53, Epoch 20/20]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "      <th>F1 Macro</th>\n",
              "      <th>F1 Micro</th>\n",
              "      <th>Jaccard Samples</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.248500</td>\n",
              "      <td>0.307931</td>\n",
              "      <td>0.713733</td>\n",
              "      <td>0.684342</td>\n",
              "      <td>0.717902</td>\n",
              "      <td>0.470843</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.247600</td>\n",
              "      <td>0.309121</td>\n",
              "      <td>0.714536</td>\n",
              "      <td>0.688455</td>\n",
              "      <td>0.721132</td>\n",
              "      <td>0.482274</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.240100</td>\n",
              "      <td>0.301949</td>\n",
              "      <td>0.725383</td>\n",
              "      <td>0.696482</td>\n",
              "      <td>0.725630</td>\n",
              "      <td>0.496055</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.232800</td>\n",
              "      <td>0.291802</td>\n",
              "      <td>0.728531</td>\n",
              "      <td>0.702502</td>\n",
              "      <td>0.734148</td>\n",
              "      <td>0.491977</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.219600</td>\n",
              "      <td>0.293441</td>\n",
              "      <td>0.729901</td>\n",
              "      <td>0.703989</td>\n",
              "      <td>0.727358</td>\n",
              "      <td>0.496923</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.209600</td>\n",
              "      <td>0.286404</td>\n",
              "      <td>0.734814</td>\n",
              "      <td>0.711123</td>\n",
              "      <td>0.740458</td>\n",
              "      <td>0.497571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.195800</td>\n",
              "      <td>0.285606</td>\n",
              "      <td>0.736218</td>\n",
              "      <td>0.711846</td>\n",
              "      <td>0.736910</td>\n",
              "      <td>0.497894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.187400</td>\n",
              "      <td>0.279428</td>\n",
              "      <td>0.740451</td>\n",
              "      <td>0.715982</td>\n",
              "      <td>0.744809</td>\n",
              "      <td>0.504788</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.174500</td>\n",
              "      <td>0.281267</td>\n",
              "      <td>0.736903</td>\n",
              "      <td>0.716027</td>\n",
              "      <td>0.740494</td>\n",
              "      <td>0.499207</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.168500</td>\n",
              "      <td>0.277723</td>\n",
              "      <td>0.744269</td>\n",
              "      <td>0.721504</td>\n",
              "      <td>0.747718</td>\n",
              "      <td>0.507763</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.164100</td>\n",
              "      <td>0.277301</td>\n",
              "      <td>0.744902</td>\n",
              "      <td>0.727837</td>\n",
              "      <td>0.749369</td>\n",
              "      <td>0.512216</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.154900</td>\n",
              "      <td>0.268770</td>\n",
              "      <td>0.749109</td>\n",
              "      <td>0.729376</td>\n",
              "      <td>0.750853</td>\n",
              "      <td>0.518472</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.149500</td>\n",
              "      <td>0.273341</td>\n",
              "      <td>0.747896</td>\n",
              "      <td>0.727463</td>\n",
              "      <td>0.749148</td>\n",
              "      <td>0.510009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.144500</td>\n",
              "      <td>0.272110</td>\n",
              "      <td>0.747641</td>\n",
              "      <td>0.728735</td>\n",
              "      <td>0.749853</td>\n",
              "      <td>0.510267</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.142400</td>\n",
              "      <td>0.270071</td>\n",
              "      <td>0.748046</td>\n",
              "      <td>0.727190</td>\n",
              "      <td>0.749027</td>\n",
              "      <td>0.514991</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.141400</td>\n",
              "      <td>0.268373</td>\n",
              "      <td>0.750549</td>\n",
              "      <td>0.732740</td>\n",
              "      <td>0.752446</td>\n",
              "      <td>0.517365</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.142900</td>\n",
              "      <td>0.268256</td>\n",
              "      <td>0.749652</td>\n",
              "      <td>0.731784</td>\n",
              "      <td>0.752135</td>\n",
              "      <td>0.516220</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.139300</td>\n",
              "      <td>0.267747</td>\n",
              "      <td>0.749863</td>\n",
              "      <td>0.731251</td>\n",
              "      <td>0.752131</td>\n",
              "      <td>0.516517</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.140900</td>\n",
              "      <td>0.268292</td>\n",
              "      <td>0.750973</td>\n",
              "      <td>0.732595</td>\n",
              "      <td>0.753303</td>\n",
              "      <td>0.516644</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.138500</td>\n",
              "      <td>0.267855</td>\n",
              "      <td>0.750961</td>\n",
              "      <td>0.732225</td>\n",
              "      <td>0.753042</td>\n",
              "      <td>0.516978</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "‚úÖ Student training completed in 10.9 min\n",
            "üå± Training emissions: 0.001097 kg CO‚ÇÇ\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ======================\n",
        "# STEP 7: TRAIN STUDENT WITH EMISSION TRACKING\n",
        "# ======================\n",
        "print(\"=\"*80)\n",
        "print(\"STEP 7: Training student model (TRACKED)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "def compute_metrics(p):\n",
        "    pred, labels = p\n",
        "    probs = 1 / (1 + np.exp(-pred))\n",
        "    binary = (probs > 0.5).astype(float)\n",
        "    return {\n",
        "        'f1': f1_score(labels, binary, average='weighted', zero_division=0),\n",
        "        'f1_macro': f1_score(labels, binary, average='macro', zero_division=0),\n",
        "        'f1_micro': f1_score(labels, binary, average='micro', zero_division=0),\n",
        "        \"jaccard_samples\": jaccard_score(labels, binary, average=\"samples\", zero_division=0)\n",
        "    }\n",
        "\n",
        "# Create new tracker for student\n",
        "student_tracker = EmissionsTracker(\n",
        "    project_name=\"DistilRoBERTa_distillation\",\n",
        "    output_dir=\"SustainabilityTracker/DistilRoBERTa\",\n",
        "    log_level=\"error\"\n",
        ")\n",
        "\n",
        "student_trainer = DistillationTrainer(\n",
        "    model=student_model,\n",
        "    args=student_args,\n",
        "    train_dataset=train_ds_student,\n",
        "    eval_dataset=test_ds_student,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        "    distillation_loss_fn=distillation_loss_fn\n",
        ")\n",
        "\n",
        "print(\"üöÄ Starting student training with emission tracking...\\n\")\n",
        "student_start_time = time.time()\n",
        "student_tracker.start()\n",
        "\n",
        "student_result = student_trainer.train()\n",
        "\n",
        "student_training_emissions = student_tracker.stop()\n",
        "student_train_time = time.time() - student_start_time\n",
        "\n",
        "print(f\"\\n‚úÖ Student training completed in {student_train_time/60:.1f} min\")\n",
        "print(f\"üå± Training emissions: {student_training_emissions:.6f} kg CO‚ÇÇ\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-26T01:01:22.870004Z",
          "iopub.status.busy": "2026-01-26T01:01:22.869730Z",
          "iopub.status.idle": "2026-01-26T01:01:26.468606Z",
          "shell.execute_reply": "2026-01-26T01:01:26.467934Z",
          "shell.execute_reply.started": "2026-01-26T01:01:22.869983Z"
        },
        "trusted": true,
        "id": "oWDsAAyav4eD",
        "outputId": "24232933-fbce-44d8-b88e-e5b77244bc8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "STEP 8: Student inference and threshold optimization (TRACKED)\n",
            "================================================================================\n",
            "‚úÖ Model moved to: cuda\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üéØ Optimizing student thresholds...\n",
            "\n",
            "================================================================================\n",
            "Label                       Thresh       F1   Supp\n",
            "--------------------------------------------------------------------------------\n",
            "acne                          0.70    0.776    215\n",
            "eye_contour                   0.70    0.873    101\n",
            "homogeneity                   0.40    0.573     91\n",
            "lack_firmness                 0.45    0.812    193\n",
            "lack_radiance                 0.65    0.767    233\n",
            "pores                         0.55    0.774    207\n",
            "fine_lines                    0.65    0.878    335\n",
            "wrinkles_fine-lines           0.70    0.842    282\n",
            "eye-wrinkles                  0.55    0.848    252\n",
            "undereye-bags                 0.60    0.750     68\n",
            "generic                       0.65    0.570    253\n",
            "18-34                         0.50    0.780     92\n",
            "35-54                         0.65    0.795    210\n",
            "55-99                         0.70    0.737     93\n",
            "dark_pigmentation             0.65    0.748    111\n",
            "dry                           0.45    0.760    197\n",
            "normal                        0.40    0.661    169\n",
            "oily                          0.50    0.755     97\n",
            "combination                   0.50    0.620    124\n",
            "sensitivity-high              0.60    0.728     77\n",
            "sensitivity-low               0.65    0.630    113\n",
            "no_sensitivity                0.49    0.333     14\n",
            "male                          0.40    0.863     73\n",
            "female                        0.70    0.905     94\n",
            "cleanse                       0.65    0.624     92\n",
            "prepare                       0.35    0.710    451\n",
            "treat                         0.60    0.717    282\n",
            "targeted                      0.60    0.654    163\n",
            "care                          0.40    0.696    352\n",
            "moisturize                    0.55    0.864    502\n",
            "protect                       0.50    0.842    177\n",
            "day                           0.50    0.822    138\n",
            "night                         0.65    0.887     78\n",
            "================================================================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# STEP 8: Student inference and threshold optimization (TRACKED)\n",
        "# ==============================================================================\n",
        "print(\"=\"*80)\n",
        "print(\"STEP 8: Student inference and threshold optimization (TRACKED)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# FIX 1: Explicitly move the model to the GPU\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "student_trainer.model.to(device)\n",
        "print(f\"‚úÖ Model moved to: {device}\")\n",
        "\n",
        "student_tracker.start()\n",
        "\n",
        "# FIX 2: Use the existing 'test_ds_student' dataset object\n",
        "# (It's faster and ensures 'teacher_logits' are present)\n",
        "student_preds = student_trainer.predict(test_ds_student)\n",
        "\n",
        "student_probs = 1 / (1 + np.exp(-student_preds.predictions))\n",
        "student_y_true = student_preds.label_ids\n",
        "\n",
        "# Use same threshold optimization strategy as teacher\n",
        "student_best_thresholds = []\n",
        "\n",
        "print(\"üéØ Optimizing student thresholds...\\n\")\n",
        "print(\"=\"*80)\n",
        "print(f\"{'Label':<25} {'Thresh':>8} {'F1':>8} {'Supp':>6}\")\n",
        "print(\"-\"*80)\n",
        "\n",
        "for i in range(33):\n",
        "    label_name = LABEL_COLUMNS[i]\n",
        "    support = int(student_y_true[:, i].sum())\n",
        "    weight = weights[i]\n",
        "\n",
        "    # Use weight-aware strategy\n",
        "    if weight > 10.0:\n",
        "        search_range = np.arange(0.1, 0.8, 0.03)\n",
        "    elif weight > 5.0:\n",
        "        search_range = np.arange(0.15, 0.85, 0.05)\n",
        "    else:\n",
        "        search_range = np.arange(0.25, 0.75, 0.05)\n",
        "\n",
        "    best_f1, best_t = 0, 0.5\n",
        "    for t in search_range:\n",
        "        preds_binary = (student_probs[:, i] > t).astype(float)\n",
        "        f1 = f1_score(student_y_true[:, i], preds_binary, zero_division=0)\n",
        "        if f1 > best_f1:\n",
        "            best_f1, best_t = f1, t\n",
        "\n",
        "    student_best_thresholds.append(best_t)\n",
        "    print(f\"{label_name:<25} {best_t:>8.2f} {best_f1:>8.3f} {support:>6d}\")\n",
        "\n",
        "student_inference_emissions = student_tracker.stop()\n",
        "\n",
        "print(\"=\"*80 + \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-26T01:01:26.470152Z",
          "iopub.status.busy": "2026-01-26T01:01:26.469792Z",
          "iopub.status.idle": "2026-01-26T01:01:26.498170Z",
          "shell.execute_reply": "2026-01-26T01:01:26.497590Z",
          "shell.execute_reply.started": "2026-01-26T01:01:26.470124Z"
        },
        "trusted": true,
        "id": "tOXZRSshv4eD",
        "outputId": "0caf190a-813a-4ef3-f38f-91ebeefa6846"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "STEP 9: Final student evaluation\n",
            "================================================================================\n",
            "\n",
            "üéâ STUDENT MODEL RESULTS:\n",
            "================================================================================\n",
            "üéØ Weighted F1: 76.26%\n",
            "üìä Macro F1:    74.52%\n",
            "üìà Micro F1:    76.36%\n",
            "üìà Jaccard:     52.63%\n",
            "================================================================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ======================\n",
        "# STEP 9: STUDENT EVALUATION\n",
        "# ======================\n",
        "print(\"=\"*80)\n",
        "print(\"STEP 9: Final student evaluation\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "student_final_preds = np.array([\n",
        "    (student_probs[:, i] > student_best_thresholds[i]).astype(float)\n",
        "    for i in range(33)\n",
        "]).T\n",
        "\n",
        "student_f1_w = f1_score(student_y_true, student_final_preds, average='weighted', zero_division=0)\n",
        "student_f1_ma = f1_score(student_y_true, student_final_preds, average='macro', zero_division=0)\n",
        "student_f1_mi = f1_score(student_y_true, student_final_preds, average='micro', zero_division=0)\n",
        "student_jac = float(jaccard_score(student_y_true, student_final_preds, average=\"samples\"))\n",
        "\n",
        "print(\"\\nüéâ STUDENT MODEL RESULTS:\")\n",
        "print(\"=\"*80)\n",
        "print(f\"üéØ Weighted F1: {student_f1_w*100:.2f}%\")\n",
        "print(f\"üìä Macro F1:    {student_f1_ma*100:.2f}%\")\n",
        "print(f\"üìà Micro F1:    {student_f1_mi*100:.2f}%\")\n",
        "print(f\"üìà Jaccard:     {student_jac*100:.2f}%\")\n",
        "print(\"=\"*80 + \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-26T01:06:04.268170Z",
          "iopub.status.busy": "2026-01-26T01:06:04.267846Z",
          "iopub.status.idle": "2026-01-26T01:06:04.276554Z",
          "shell.execute_reply": "2026-01-26T01:06:04.275773Z",
          "shell.execute_reply.started": "2026-01-26T01:06:04.268145Z"
        },
        "trusted": true,
        "id": "ySsw_MyHv4eD",
        "outputId": "49d3ffb0-7e2b-42ff-8a55-ef2dec4aabce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "STEP 10: Teacher vs Student comparison\n",
            "================================================================================\n",
            "\n",
            "üìä PERFORMANCE COMPARISON:\n",
            "--------------------------------------------------------------------------------\n",
            "Metric                         Teacher      Student    Retention\n",
            "--------------------------------------------------------------------------------\n",
            "Weighted F1                     78.17%       76.26%        97.6%\n",
            "Macro F1                        76.98%       74.52%        96.8%\n",
            "Micro F1                        78.21%       76.36%        97.6%\n",
            "Jaccard                         55.79%       52.63%        94.3%\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "üå± SUSTAINABILITY COMPARISON:\n",
            "--------------------------------------------------------------------------------\n",
            "Metric                            Teacher         Student    Reduction\n",
            "--------------------------------------------------------------------------------\n",
            "Training emissions              0.031781       0.001097        96.5%\n",
            "Training time (min)                107.0           10.9        89.8%\n",
            "Model parameters              355,393,569      82,143,777        76.9%\n",
            "--------------------------------------------------------------------------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ======================\n",
        "# STEP 10: COMPARISON ANALYSIS\n",
        "# ======================\n",
        "print(\"=\"*80)\n",
        "print(\"STEP 10: Teacher vs Student comparison\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Teacher Metrics\n",
        "f1_w = 0.7817           # Teacher Weighted F1\n",
        "f1_ma = 0.7698          # Teacher Macro F1\n",
        "f1_mi = 0.7821          # Teacher Micro F1\n",
        "test_jac = 0.5579       # Teacher Jaccard Score\n",
        "\n",
        "training_emissions = 0.031781  # Teacher Emissions (kg)\n",
        "teacher_train_time = 214 * 30   # Teacher Time in seconds (e.g., 30 mins)\n",
        "\n",
        "f1_retention = (student_f1_ma / f1_ma) * 100 if f1_ma > 0 else 0\n",
        "emissions_reduction = ((training_emissions - student_training_emissions) / training_emissions) * 100 if training_emissions > 0 else 0\n",
        "time_reduction = ((teacher_train_time - student_result.metrics['train_runtime']) / teacher_train_time) * 100\n",
        "\n",
        "print(\"\\nüìä PERFORMANCE COMPARISON:\")\n",
        "print(\"-\"*80)\n",
        "print(f\"{'Metric':<25} {'Teacher':>12} {'Student':>12} {'Retention':>12}\")\n",
        "print(\"-\"*80)\n",
        "print(f\"{'Weighted F1':<25} {f1_w*100:>11.2f}% {student_f1_w*100:>11.2f}% {(student_f1_w/f1_w)*100:>11.1f}%\")\n",
        "print(f\"{'Macro F1':<25} {f1_ma*100:>11.2f}% {student_f1_ma*100:>11.2f}% {f1_retention:>11.1f}%\")\n",
        "print(f\"{'Micro F1':<25} {f1_mi*100:>11.2f}% {student_f1_mi*100:>11.2f}% {(student_f1_mi/f1_mi)*100:>11.1f}%\")\n",
        "print(f\"{'Jaccard':<25} {test_jac*100:>11.2f}% {student_jac*100:>11.2f}% {(student_jac/test_jac)*100:>11.1f}%\")\n",
        "print(\"-\"*80 + \"\\n\")\n",
        "\n",
        "print(\"üå± SUSTAINABILITY COMPARISON:\")\n",
        "print(\"-\"*80)\n",
        "print(f\"{'Metric':<25} {'Teacher':>15} {'Student':>15} {'Reduction':>12}\")\n",
        "print(\"-\"*80)\n",
        "print(f\"{'Training emissions':<25} {training_emissions:>14.6f} {student_training_emissions:>14.6f} {emissions_reduction:>11.1f}%\")\n",
        "print(f\"{'Training time (min)':<25} {teacher_train_time/60:>14.1f} {student_result.metrics['train_runtime']/60:>14.1f} {time_reduction:>11.1f}%\")\n",
        "print(f\"{'Model parameters':<25} {teacher_params:>15,} {student_params:>15,} {compression_ratio:>11.1f}%\")\n",
        "print(\"-\"*80 + \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-26T01:06:11.518901Z",
          "iopub.status.busy": "2026-01-26T01:06:11.518312Z",
          "iopub.status.idle": "2026-01-26T01:06:11.834348Z",
          "shell.execute_reply": "2026-01-26T01:06:11.833641Z",
          "shell.execute_reply.started": "2026-01-26T01:06:11.518850Z"
        },
        "trusted": true,
        "id": "8cGjiozvv4eD",
        "outputId": "bc16006a-9117-4097-b67d-6c7120dcc03c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "STEP 11: Quantizing student model for production\n",
            "================================================================================\n",
            "‚úÖ Model quantized to INT8\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ======================\n",
        "# STEP 11: MODEL QUANTIZATION\n",
        "# ======================\n",
        "print(\"=\"*80)\n",
        "print(\"STEP 11: Quantizing student model for production\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Dynamic INT8 quantization\n",
        "student_model_cpu = student_model.cpu()\n",
        "quantized_model = torch.quantization.quantize_dynamic(\n",
        "    student_model_cpu,\n",
        "    {nn.Linear},\n",
        "    dtype=torch.qint8\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Model quantized to INT8\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "783b-kFiv4eE",
        "outputId": "46963a5b-11ca-4ced-991d-925e9e1d868e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "STEP 12: Saving student model artifacts\n",
            "================================================================================\n",
            "üíæ Model sizes:\n",
            "   Teacher (unquantized): 1360.4 MB\n",
            "   Student (quantized): 190.2 MB\n",
            "   Size reduction: 86.0%\n",
            "\n",
            "‚úÖ All artifacts saved to ./DistilRoBERTa_final/\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ======================\n",
        "# STEP 12: SAVE EVERYTHING\n",
        "# ======================\n",
        "print(\"=\"*80)\n",
        "print(\"STEP 12: Saving student model artifacts\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Save quantized model\n",
        "os.makedirs(\"./DistilRoBERTa_final\", exist_ok=True)\n",
        "torch.save(quantized_model.state_dict(), \"./DistilRoBERTa_final/quantized_model.pth\")\n",
        "student_tokenizer.save_pretrained(\"./DistilRoBERTa_final\")\n",
        "np.save(\"./DistilRoBERTa_final/student_thresholds.npy\", student_best_thresholds)\n",
        "\n",
        "# Save comparison results\n",
        "comparison_results = pd.DataFrame([{\n",
        "    'model': 'Teacher (RoBERTa-large)',\n",
        "    'parameters': teacher_params,\n",
        "    'weighted_f1': f1_w,\n",
        "    'macro_f1': f1_ma,\n",
        "    'micro_f1': f1_mi,\n",
        "    'jaccard': test_jac,\n",
        "    'training_emissions_kg': training_emissions,\n",
        "    'training_time_min': teacher_train_time/60\n",
        "}, {\n",
        "    'model': 'Student (MiniLM-L12)',\n",
        "    'parameters': student_params,\n",
        "    'weighted_f1': student_f1_w,\n",
        "    'macro_f1': student_f1_ma,\n",
        "    'micro_f1': student_f1_mi,\n",
        "    'jaccard': student_jac,\n",
        "    'training_emissions_kg': student_training_emissions,\n",
        "    'training_time_min': student_result.metrics['train_runtime']/60\n",
        "}])\n",
        "\n",
        "comparison_results.to_csv(\"./DistilRoBERTa_final/teacher_student_comparison.csv\", index=False)\n",
        "\n",
        "# Model size comparison\n",
        "try:\n",
        "    teacher_size = sum(os.path.getsize(os.path.join(\"./models/RoBERTa_final\", f))\n",
        "                       for f in os.listdir(\"./models/RoBERTa_final\")\n",
        "                       if os.path.isfile(os.path.join(\"./models/RoBERTa_final\", f)))\n",
        "    student_size = os.path.getsize(\"./DistilRoBERTa_final/quantized_model.pth\")\n",
        "\n",
        "    print(f\"üíæ Model sizes:\")\n",
        "    print(f\"   Teacher (unquantized): {teacher_size / (1024**2):.1f} MB\")\n",
        "    print(f\"   Student (quantized): {student_size / (1024**2):.1f} MB\")\n",
        "    print(f\"   Size reduction: {(1 - student_size/teacher_size)*100:.1f}%\\n\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è  Could not calculate model sizes: {e}\\n\")\n",
        "\n",
        "print(\"‚úÖ All artifacts saved to ./DistilRoBERTa_final/\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-01-26T01:06:19.881085Z",
          "iopub.status.busy": "2026-01-26T01:06:19.880434Z",
          "iopub.status.idle": "2026-01-26T01:06:19.886501Z",
          "shell.execute_reply": "2026-01-26T01:06:19.885649Z",
          "shell.execute_reply.started": "2026-01-26T01:06:19.881053Z"
        },
        "trusted": true,
        "id": "8Z2q78Hwv4eE",
        "outputId": "67093348-2636-4f5e-94d9-8eaa07335608"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "üéâ KNOWLEDGE DISTILLATION COMPLETE\n",
            "================================================================================\n",
            "\n",
            "‚ú® ACHIEVEMENTS:\n",
            "   ‚Ä¢ F1 Score retention: 96.8%\n",
            "   ‚Ä¢ Emissions reduction: 96.5%\n",
            "   ‚Ä¢ Model size reduction: 76.9%\n",
            "   ‚Ä¢ Training time reduction: 89.8%\n",
            "\n",
            "üå± SUSTAINABILITY IMPACT:\n",
            "   ‚Ä¢ Student emissions: 0.001097 kg CO‚ÇÇ\n",
            "   ‚Ä¢ Suitable for production deployment\n",
            "   ‚Ä¢ Fast inference on CPU\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ======================\n",
        "# FINAL SUMMARY\n",
        "# ======================\n",
        "print(\"=\"*80)\n",
        "print(\"üéâ KNOWLEDGE DISTILLATION COMPLETE\")\n",
        "print(\"=\"*80)\n",
        "print(f\"\"\"\n",
        "‚ú® ACHIEVEMENTS:\n",
        "   ‚Ä¢ F1 Score retention: {f1_retention:.1f}%\n",
        "   ‚Ä¢ Emissions reduction: {emissions_reduction:.1f}%\n",
        "   ‚Ä¢ Model size reduction: {compression_ratio:.1f}%\n",
        "   ‚Ä¢ Training time reduction: {time_reduction:.1f}%\n",
        "\n",
        "üå± SUSTAINABILITY IMPACT:\n",
        "   ‚Ä¢ Student emissions: {student_training_emissions:.6f} kg CO‚ÇÇ\n",
        "   ‚Ä¢ Suitable for production deployment\n",
        "   ‚Ä¢ Fast inference on CPU\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "3aQN1h1Nv4eE"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "datasetId": 9334078,
          "sourceId": 14613001,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 9337539,
          "sourceId": 14618534,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 31260,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": ".venv (3.11.7)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}