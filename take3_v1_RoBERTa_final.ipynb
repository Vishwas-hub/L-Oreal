{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 14613001,
          "sourceType": "datasetVersion",
          "datasetId": 9334078
        }
      ],
      "dockerImageVersionId": 31260,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import warnings\n",
        "import time\n",
        "import os\n",
        "\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, jaccard_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from datasets import Dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer\n",
        ")\n",
        "from codecarbon import EmissionsTracker"
      ],
      "metadata": {
        "id": "lGnPHrACa8FR",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-25T18:57:27.268275Z",
          "iopub.execute_input": "2026-01-25T18:57:27.268563Z",
          "iopub.status.idle": "2026-01-25T18:57:27.273375Z",
          "shell.execute_reply.started": "2026-01-25T18:57:27.268542Z",
          "shell.execute_reply": "2026-01-25T18:57:27.272690Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-25T18:57:27.306051Z",
          "iopub.execute_input": "2026-01-25T18:57:27.306655Z",
          "iopub.status.idle": "2026-01-25T18:57:27.309635Z",
          "shell.execute_reply.started": "2026-01-25T18:57:27.306631Z",
          "shell.execute_reply": "2026-01-25T18:57:27.309052Z"
        },
        "id": "x3N9P2YXv8HX"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"‚úÖ PyTorch: {torch.__version__}\")\n",
        "print(f\"‚úÖ CUDA: {torch.cuda.is_available()}\")\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"‚úÖ Device: {device}\\n\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-25T18:57:27.354971Z",
          "iopub.execute_input": "2026-01-25T18:57:27.355284Z",
          "iopub.status.idle": "2026-01-25T18:57:27.359955Z",
          "shell.execute_reply.started": "2026-01-25T18:57:27.355262Z",
          "shell.execute_reply": "2026-01-25T18:57:27.359142Z"
        },
        "id": "uDYdvQqHv8HX",
        "outputId": "a9b4e609-a272-4ba1-e5da-e907b9358708"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "‚úÖ PyTorch: 2.8.0+cu126\n‚úÖ CUDA: True\n‚úÖ Device: cuda\n\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================\n",
        "# LOAD DATA\n",
        "# ======================\n",
        "print(\"üìÇ Loading data...\")\n",
        "df = pd.read_excel(\"/kaggle/input/dataset-v1/dataset.xlsx\")\n",
        "df = df.dropna(subset=[\"text_raw\"]).rename(columns={\"text_raw\": \"text\"})\n",
        "\n",
        "# ======================\n",
        "# PREPROCESSING\n",
        "# ======================\n",
        "def advanced_clean(text):\n",
        "    if pd.isna(text): return \"\"\n",
        "    text = str(text)\n",
        "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
        "    text = re.sub(r'\\S+@\\S+', '', text)\n",
        "    text = re.sub(r'<.*?>', '', text)\n",
        "    text = re.sub(r'[^\\w\\s\\-\\.\\,\\!\\?\\%]', ' ', text)\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    text = text.lower().strip()\n",
        "    if len(text.split()) < 3: return \"\"\n",
        "    return text\n",
        "\n",
        "\n",
        "LABEL_COLUMNS = [\n",
        "    \"acne\", \"eye_contour\", \"homogeneity\", \"lack_firmness\", \"lack_radiance\",\n",
        "    \"pores\", \"fine_lines\", \"wrinkles_fine-lines\", \"eye-wrinkles\", \"undereye-bags\",\n",
        "    \"generic\", \"18-34\", \"35-54\", \"55-99\", \"dark_pigmentation\", \"dry\", \"normal\",\n",
        "    \"oily\", \"combination\", \"sensitivity-high\", \"sensitivity-low\", \"no_sensitivity\",\n",
        "    \"male\", \"female\", \"cleanse\", \"prepare\", \"treat\", \"targeted\", \"care\",\n",
        "    \"moisturize\", \"protect\", \"day\", \"night\"\n",
        "]\n",
        "\n",
        "print(\"üßπ Preprocessing...\")\n",
        "\n",
        "# ======================\n",
        "# DATA PRUNING\n",
        "# ======================\n",
        "MAX_LABELS_PER_SAMPLE = 20  # more than 60% of labels\n",
        "\n",
        "# Ensure labels are numeric and NaNs are treated as 0\n",
        "label_matrix = df[LABEL_COLUMNS].fillna(0).astype(int)\n",
        "\n",
        "# Count active labels per sample\n",
        "labels_per_sample = label_matrix.sum(axis=1)\n",
        "\n",
        "before_n = len(df)\n",
        "removed_mask = labels_per_sample > MAX_LABELS_PER_SAMPLE\n",
        "removed_n = int(removed_mask.sum())\n",
        "removed_pct = (100.0 * removed_n / before_n) if before_n > 0 else 0.0\n",
        "\n",
        "# Prune\n",
        "df = df.loc[~removed_mask].copy().reset_index(drop=True)\n",
        "label_matrix = label_matrix.loc[df.index]\n",
        "\n",
        "print(f\"Pruning rule: keep samples with ‚â§ {MAX_LABELS_PER_SAMPLE} labels\")\n",
        "print(f\"Before: {before_n} | Removed: {removed_n} ({removed_pct:.2f}%) | After: {len(df)}\")\n",
        "print(\"Labels/sample (after) - mean:\", round(label_matrix.sum(axis=1).mean(), 3))\n",
        "print(\"Labels/sample (after) - max:\", int(label_matrix.sum(axis=1).max()))\n",
        "\n",
        "df[\"cleaned_text\"] = df[\"text\"].apply(advanced_clean)\n",
        "df = df[df[\"cleaned_text\"].str.len() > 0]\n",
        "df[\"labels\"] = df[LABEL_COLUMNS].apply(lambda row: row.tolist(), axis=1)\n",
        "print(f\"   Samples: {len(df)}\\n\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-25T18:57:27.394461Z",
          "iopub.execute_input": "2026-01-25T18:57:27.394688Z",
          "iopub.status.idle": "2026-01-25T18:57:29.993393Z",
          "shell.execute_reply.started": "2026-01-25T18:57:27.394668Z",
          "shell.execute_reply": "2026-01-25T18:57:29.992672Z"
        },
        "id": "lb4LW-OIv8HX",
        "outputId": "d2cbcf8f-7551-44cf-b1e7-28474af821b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "üìÇ Loading data...\nüßπ Preprocessing...\nPruning rule: keep samples with ‚â§ 20 labels\nBefore: 6240 | Removed: 16 (0.26%) | After: 6224\nLabels/sample (after) - mean: 3.965\nLabels/sample (after) - max: 33\n   Samples: 6224\n\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================\n",
        "# OVERSAMPLE RARE AGE & GENDER LABELS\n",
        "# ======================\n",
        "print(\"üîÑ Oversampling rare age & gender labels...\")\n",
        "\n",
        "# Define age and gender labels\n",
        "AGE_LABELS = [\"18-34\", \"35-54\", \"55-99\"]\n",
        "GENDER_LABELS = [\"male\", \"female\"]\n",
        "RARE_LABELS = AGE_LABELS + GENDER_LABELS\n",
        "\n",
        "# Calculate support for each label\n",
        "label_counts = df[RARE_LABELS].sum()\n",
        "print(\"\\nBefore oversampling:\")\n",
        "print(label_counts)\n",
        "\n",
        "# Define oversampling strategy\n",
        "TARGET_MIN_SAMPLES = 500  # Target minimum samples per label\n",
        "oversample_factor = {}\n",
        "\n",
        "for label in RARE_LABELS:\n",
        "    count = label_counts[label]\n",
        "    if count < TARGET_MIN_SAMPLES and count > 0:\n",
        "        oversample_factor[label] = int(TARGET_MIN_SAMPLES / count)\n",
        "    else:\n",
        "        oversample_factor[label] = 0\n",
        "\n",
        "print(f\"\\nOversampling factors: {oversample_factor}\")\n",
        "\n",
        "# Perform oversampling\n",
        "df_original = df.copy()\n",
        "samples_to_add = []\n",
        "\n",
        "for label, factor in oversample_factor.items():\n",
        "    if factor > 1:\n",
        "        # Get samples with this label\n",
        "        label_samples = df[df[label] == 1]\n",
        "\n",
        "        # Replicate (factor - 1) times (we already have original)\n",
        "        for _ in range(factor - 1):\n",
        "            samples_to_add.append(label_samples)\n",
        "\n",
        "        print(f\"   {label}: {len(label_samples)} ‚Üí {len(label_samples) * factor}\")\n",
        "\n",
        "# Concatenate all samples\n",
        "if samples_to_add:\n",
        "    df = pd.concat([df] + samples_to_add, ignore_index=True)\n",
        "\n",
        "    # Shuffle to avoid clustering\n",
        "    df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "print(f\"\\nDataset size: {len(df_original)} ‚Üí {len(df)} (+{len(df) - len(df_original)})\")\n",
        "print(\"\\nAfter oversampling:\")\n",
        "print(df[RARE_LABELS].sum())\n",
        "print()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-25T18:57:29.994744Z",
          "iopub.execute_input": "2026-01-25T18:57:29.995015Z",
          "iopub.status.idle": "2026-01-25T18:57:30.015971Z",
          "shell.execute_reply.started": "2026-01-25T18:57:29.994994Z",
          "shell.execute_reply": "2026-01-25T18:57:30.015266Z"
        },
        "id": "E8k-kM_fv8HY",
        "outputId": "b0cadac3-b1af-4fa7-80e5-f8a8523502fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "üîÑ Oversampling rare age & gender labels...\n\nBefore oversampling:\n18-34     182\n35-54     800\n55-99     262\nmale      335\nfemale    113\ndtype: int64\n\nOversampling factors: {'18-34': 2, '35-54': 0, '55-99': 1, 'male': 1, 'female': 4}\n   18-34: 182 ‚Üí 364\n   female: 113 ‚Üí 452\n\nDataset size: 6224 ‚Üí 6745 (+521)\n\nAfter oversampling:\n18-34      430\n35-54     1038\n55-99      424\nmale       350\nfemale     474\ndtype: int64\n\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================\n",
        "# CLASS WEIGHTS\n",
        "# ======================\n",
        "y = np.array(df[LABEL_COLUMNS].values, dtype=np.float32)\n",
        "pos = y.sum(axis=0)\n",
        "weights = []\n",
        "for i in range(len(LABEL_COLUMNS)):\n",
        "    if pos[i] < 50: w = min(20.0, (len(df) - pos[i]) / (pos[i] + 1))  # Increased from 15\n",
        "    elif pos[i] < 100: w = min(12.0, (len(df) - pos[i]) / (pos[i] + 1))  # NEW bracket\n",
        "    elif pos[i] < 200: w = min(8.0, (len(df) - pos[i]) / (pos[i] + 1))\n",
        "    else: w = min(3.0, (len(df) - pos[i]) / (pos[i] + 1))\n",
        "    weights.append(w)\n",
        "\n",
        "class_weights = torch.tensor(weights, dtype=torch.float32).to(device)\n",
        "print(f\"‚öñÔ∏è  Weights: {min(weights):.2f} - {max(weights):.2f}\\n\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-25T18:57:30.016921Z",
          "iopub.execute_input": "2026-01-25T18:57:30.017225Z",
          "iopub.status.idle": "2026-01-25T18:57:30.025437Z",
          "shell.execute_reply.started": "2026-01-25T18:57:30.017195Z",
          "shell.execute_reply": "2026-01-25T18:57:30.024785Z"
        },
        "id": "1w0T540Nv8HY",
        "outputId": "417c8c50-78ef-4513-de5e-57de8a8bd684"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "‚öñÔ∏è  Weights: 1.60 - 12.00\n\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================\n",
        "# SPLIT\n",
        "# ======================\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df[LABEL_COLUMNS[0]])\n",
        "print(f\"‚úÇÔ∏è  Train: {len(train_df)} | Test: {len(test_df)}\\n\")\n",
        "\n",
        "train_ds = Dataset.from_pandas(train_df[[\"cleaned_text\", \"labels\"]].reset_index(drop=True))\n",
        "test_ds = Dataset.from_pandas(test_df[[\"cleaned_text\", \"labels\"]].reset_index(drop=True))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-25T18:57:30.026875Z",
          "iopub.execute_input": "2026-01-25T18:57:30.027085Z",
          "iopub.status.idle": "2026-01-25T18:57:30.118448Z",
          "shell.execute_reply.started": "2026-01-25T18:57:30.027067Z",
          "shell.execute_reply": "2026-01-25T18:57:30.117562Z"
        },
        "id": "XlNotj8Kv8HY",
        "outputId": "b85d89f0-7ecb-4ec5-d49a-357f057674db"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "‚úÇÔ∏è  Train: 5396 | Test: 1349\n\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================\n",
        "# DEFINE EMISSIONS TRACKER\n",
        "# ======================\n",
        "os.makedirs(\"/kaggle/working/EmissionsTracker\", exist_ok=True)\n",
        "\n",
        "tracker = EmissionsTracker(\n",
        "    project_name=\"roberta_large_eval\",\n",
        "    output_dir=\"/kaggle/working/EmissionsTracker\",\n",
        "    log_level=\"error\"\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-25T18:57:30.119422Z",
          "iopub.execute_input": "2026-01-25T18:57:30.119722Z",
          "iopub.status.idle": "2026-01-25T18:57:33.309088Z",
          "shell.execute_reply.started": "2026-01-25T18:57:30.119679Z",
          "shell.execute_reply": "2026-01-25T18:57:33.308332Z"
        },
        "id": "qKzYRmkQv8HZ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================\n",
        "# MODEL CONFIGURATION\n",
        "# ======================\n",
        "MODEL_NAME = \"roberta-large\"\n",
        "MAX_LENGTH = 256\n",
        "BATCH_SIZE = 4\n",
        "GRAD_ACCUM = 8\n",
        "EPOCHS = 25\n",
        "LEARNING_RATE = 3e-5\n",
        "\n",
        "print(f\"üéØ MODEL CONFIGURATION:\")\n",
        "print(f\"   Model: {MODEL_NAME}\")\n",
        "print(f\"   Epochs: {EPOCHS}\")\n",
        "print(f\"   Effective batch: {BATCH_SIZE * GRAD_ACCUM}\")\n",
        "print(f\"   Learning rate: {LEARNING_RATE}\")\n",
        "print(f\"   Max length: {MAX_LENGTH}\\n\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-25T19:03:01.175822Z",
          "iopub.execute_input": "2026-01-25T19:03:01.176314Z",
          "iopub.status.idle": "2026-01-25T19:03:01.181298Z",
          "shell.execute_reply.started": "2026-01-25T19:03:01.176286Z",
          "shell.execute_reply": "2026-01-25T19:03:01.180554Z"
        },
        "id": "5w-ij4gev8HZ",
        "outputId": "039deb30-02f5-4e73-d27e-b07134084cba"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "üéØ MODEL CONFIGURATION:\n   Model: roberta-large\n   Epochs: 25\n   Effective batch: 32\n   Learning rate: 3e-05\n   Max length: 256\n\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================\n",
        "# TOKENIZE\n",
        "# ======================\n",
        "print(\"üî§ Tokenizing...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "def tokenize(x):\n",
        "    return tokenizer(x[\"cleaned_text\"], padding=\"max_length\", truncation=True, max_length=MAX_LENGTH)\n",
        "\n",
        "train_tok = train_ds.map(tokenize, batched=True, remove_columns=[\"cleaned_text\"])\n",
        "test_tok = test_ds.map(tokenize, batched=True, remove_columns=[\"cleaned_text\"])\n",
        "train_tok.set_format(\"torch\")\n",
        "test_tok.set_format(\"torch\")\n",
        "print(\"‚úÖ Done\\n\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-25T19:03:03.001204Z",
          "iopub.execute_input": "2026-01-25T19:03:03.001983Z",
          "iopub.status.idle": "2026-01-25T19:03:05.324903Z",
          "shell.execute_reply.started": "2026-01-25T19:03:03.001954Z",
          "shell.execute_reply": "2026-01-25T19:03:05.324021Z"
        },
        "id": "ORIW1q1av8HZ",
        "outputId": "7ac83d9e-22ee-4323-c1e0-85b98170f0be",
        "colab": {
          "referenced_widgets": [
            "0dec0a967e1940dab9b15999ce8c2f5a",
            "36a95e5226dd47faaad17c7f1b82111b"
          ]
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "üî§ Tokenizing...\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map:   0%|          | 0/5396 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0dec0a967e1940dab9b15999ce8c2f5a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map:   0%|          | 0/1349 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "36a95e5226dd47faaad17c7f1b82111b"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "   ‚úÖ Done\n\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================\n",
        "# FOCAL LOSS\n",
        "# ======================\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, alpha=0.25, gamma=2.0, pos_weight=None):\n",
        "        super().__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.pos_weight = pos_weight\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        bce = nn.functional.binary_cross_entropy_with_logits(\n",
        "            inputs, targets, reduction='none', pos_weight=self.pos_weight\n",
        "        )\n",
        "        pt = torch.exp(-bce)\n",
        "        return (self.alpha * (1 - pt) ** self.gamma * bce).mean()\n",
        "\n",
        "class AdvancedTrainer(Trainer):\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
        "        labels = inputs.pop(\"labels\").float()\n",
        "        outputs = model(**inputs)\n",
        "        loss = FocalLoss(alpha=0.25, gamma=2.0, pos_weight=class_weights)(outputs.logits, labels)\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "def compute_metrics(p):\n",
        "    pred, labels = p\n",
        "    probs = 1 / (1 + np.exp(-pred))\n",
        "    binary = (probs > 0.5).astype(float)\n",
        "    return {\n",
        "        'f1': f1_score(labels, binary, average='weighted', zero_division=0),\n",
        "        'f1_macro': f1_score(labels, binary, average='macro', zero_division=0),\n",
        "        'f1_micro': f1_score(labels, binary, average='micro', zero_division=0),\n",
        "        \"jaccard_samples\": jaccard_score(labels, binary, average=\"samples\", zero_division=0)\n",
        "    }"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-25T19:03:08.598925Z",
          "iopub.execute_input": "2026-01-25T19:03:08.599639Z",
          "iopub.status.idle": "2026-01-25T19:03:08.608494Z",
          "shell.execute_reply.started": "2026-01-25T19:03:08.599612Z",
          "shell.execute_reply": "2026-01-25T19:03:08.607722Z"
        },
        "id": "Fo_Sy-Zgv8HZ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================\n",
        "# LOAD MODEL\n",
        "# ======================\n",
        "print(\"ü§ñ Loading RoBERTa-large...\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    MODEL_NAME, num_labels=33, problem_type=\"multi_label_classification\", ignore_mismatched_sizes=True\n",
        ")\n",
        "print(f\"   Parameters: {sum(p.numel() for p in model.parameters()):,}\\n\")\n",
        "\n",
        "# ======================\n",
        "# TRAINING ARGS\n",
        "# ======================\n",
        "args = TrainingArguments(\n",
        "    output_dir=\"./roberta_final\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    per_device_train_batch_size=BATCH_SIZE,\n",
        "    per_device_eval_batch_size=8,\n",
        "    gradient_accumulation_steps=GRAD_ACCUM,\n",
        "    num_train_epochs=EPOCHS,\n",
        "    weight_decay=0.01,\n",
        "    warmup_ratio=0.2,              # NEW: More warmup\n",
        "    max_grad_norm=1.0,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1\",\n",
        "    greater_is_better=True,\n",
        "    logging_steps=50,\n",
        "    save_total_limit=1,\n",
        "    fp16=True,\n",
        "    report_to=\"none\",\n",
        "    seed=42,\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-25T19:03:24.214982Z",
          "iopub.execute_input": "2026-01-25T19:03:24.215671Z",
          "iopub.status.idle": "2026-01-25T19:03:24.531966Z",
          "shell.execute_reply.started": "2026-01-25T19:03:24.215641Z",
          "shell.execute_reply": "2026-01-25T19:03:24.531386Z"
        },
        "id": "_jm0JHrVv8HZ",
        "outputId": "cc8008f4-94a0-4614-d713-9bab6344ed00"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "ü§ñ Loading RoBERTa-large...\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "   Parameters: 355,393,569\n\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================\n",
        "# TRAIN THE MODEL AND SUSTAINIBILITY TRACKING (TRAINING)\n",
        "# ======================\n",
        "print(\"=\"*80)\n",
        "print(\"üöÄ STARTING MODEL TRAINING\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "trainer = AdvancedTrainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=train_tok,\n",
        "    eval_dataset=test_tok,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "# START sustainability tracking (training)\n",
        "train_start_time = time.time()\n",
        "tracker.start()\n",
        "\n",
        "result = trainer.train()\n",
        "\n",
        "training_emissions = tracker.stop()\n",
        "train_end_time = time.time()\n",
        "\n",
        "print(f\"\\n‚úÖ Completed {EPOCHS} epochs in {result.metrics['train_runtime']/60:.1f} min\\n\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-25T19:03:28.990963Z",
          "iopub.execute_input": "2026-01-25T19:03:28.991288Z",
          "iopub.status.idle": "2026-01-25T22:37:33.589365Z",
          "shell.execute_reply.started": "2026-01-25T19:03:28.991259Z",
          "shell.execute_reply": "2026-01-25T22:37:33.588173Z"
        },
        "id": "aWAaPRaVv8Ha",
        "outputId": "1a35e737-7f3a-4d2a-f127-15b3b60c0c2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "================================================================================\nüöÄ STARTING MODEL TRAINING\n================================================================================\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='4225' max='4225' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [4225/4225 3:34:00, Epoch 25/25]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>F1</th>\n      <th>F1 Macro</th>\n      <th>F1 Micro</th>\n      <th>Jaccard Samples</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.079900</td>\n      <td>0.065602</td>\n      <td>0.440556</td>\n      <td>0.351467</td>\n      <td>0.447444</td>\n      <td>0.252900</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.053300</td>\n      <td>0.045710</td>\n      <td>0.632664</td>\n      <td>0.602616</td>\n      <td>0.628894</td>\n      <td>0.406132</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.041400</td>\n      <td>0.039340</td>\n      <td>0.667863</td>\n      <td>0.638685</td>\n      <td>0.653598</td>\n      <td>0.431751</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.037300</td>\n      <td>0.037679</td>\n      <td>0.670165</td>\n      <td>0.637283</td>\n      <td>0.655429</td>\n      <td>0.439792</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.033900</td>\n      <td>0.036461</td>\n      <td>0.699559</td>\n      <td>0.677153</td>\n      <td>0.692503</td>\n      <td>0.473465</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.028800</td>\n      <td>0.036456</td>\n      <td>0.669061</td>\n      <td>0.637134</td>\n      <td>0.649327</td>\n      <td>0.446402</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.024300</td>\n      <td>0.034552</td>\n      <td>0.729194</td>\n      <td>0.707707</td>\n      <td>0.723120</td>\n      <td>0.506547</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.020600</td>\n      <td>0.035498</td>\n      <td>0.737938</td>\n      <td>0.720626</td>\n      <td>0.733348</td>\n      <td>0.510750</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.016500</td>\n      <td>0.035487</td>\n      <td>0.731240</td>\n      <td>0.713749</td>\n      <td>0.726313</td>\n      <td>0.504944</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.014300</td>\n      <td>0.035831</td>\n      <td>0.743977</td>\n      <td>0.729096</td>\n      <td>0.740997</td>\n      <td>0.520806</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>0.011200</td>\n      <td>0.038018</td>\n      <td>0.748883</td>\n      <td>0.732033</td>\n      <td>0.747906</td>\n      <td>0.524233</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>0.009500</td>\n      <td>0.039676</td>\n      <td>0.756229</td>\n      <td>0.738487</td>\n      <td>0.754017</td>\n      <td>0.534141</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>0.007700</td>\n      <td>0.040740</td>\n      <td>0.760632</td>\n      <td>0.744073</td>\n      <td>0.758550</td>\n      <td>0.533164</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>0.006600</td>\n      <td>0.041020</td>\n      <td>0.756285</td>\n      <td>0.734466</td>\n      <td>0.754772</td>\n      <td>0.535760</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>0.005200</td>\n      <td>0.043597</td>\n      <td>0.759392</td>\n      <td>0.743688</td>\n      <td>0.760267</td>\n      <td>0.536996</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>0.004500</td>\n      <td>0.044044</td>\n      <td>0.764619</td>\n      <td>0.749581</td>\n      <td>0.764125</td>\n      <td>0.541967</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>0.003900</td>\n      <td>0.046406</td>\n      <td>0.764795</td>\n      <td>0.748151</td>\n      <td>0.766069</td>\n      <td>0.541275</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>0.003400</td>\n      <td>0.046546</td>\n      <td>0.766783</td>\n      <td>0.751766</td>\n      <td>0.767982</td>\n      <td>0.548387</td>\n    </tr>\n    <tr>\n      <td>19</td>\n      <td>0.002900</td>\n      <td>0.048112</td>\n      <td>0.770513</td>\n      <td>0.754772</td>\n      <td>0.772356</td>\n      <td>0.547658</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>0.002600</td>\n      <td>0.047740</td>\n      <td>0.765588</td>\n      <td>0.749654</td>\n      <td>0.766811</td>\n      <td>0.539134</td>\n    </tr>\n    <tr>\n      <td>21</td>\n      <td>0.002300</td>\n      <td>0.048043</td>\n      <td>0.770180</td>\n      <td>0.754495</td>\n      <td>0.771623</td>\n      <td>0.548475</td>\n    </tr>\n    <tr>\n      <td>22</td>\n      <td>0.002100</td>\n      <td>0.049366</td>\n      <td>0.769051</td>\n      <td>0.753412</td>\n      <td>0.770485</td>\n      <td>0.543692</td>\n    </tr>\n    <tr>\n      <td>23</td>\n      <td>0.002000</td>\n      <td>0.049757</td>\n      <td>0.769634</td>\n      <td>0.753853</td>\n      <td>0.771365</td>\n      <td>0.544919</td>\n    </tr>\n    <tr>\n      <td>24</td>\n      <td>0.001900</td>\n      <td>0.049864</td>\n      <td>0.771464</td>\n      <td>0.755826</td>\n      <td>0.773130</td>\n      <td>0.546466</td>\n    </tr>\n    <tr>\n      <td>25</td>\n      <td>0.001700</td>\n      <td>0.050074</td>\n      <td>0.771785</td>\n      <td>0.756845</td>\n      <td>0.773574</td>\n      <td>0.547701</td>\n    </tr>\n  </tbody>\n</table><p>"
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "\n‚úÖ Completed 25 epochs in 214.0 min\n\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================\n",
        "# STORE WEIGHTS FOR THRESHOLD TUNING\n",
        "# ======================\n",
        "# Save weights for use during threshold optimization\n",
        "weights_dict = {label: weight for label, weight in zip(LABEL_COLUMNS, weights)}\n",
        "print(\"\\nüìä High-weight labels (will get special threshold tuning):\")\n",
        "high_weight_labels = [(label, w) for label, w in weights_dict.items() if w > 5.0]\n",
        "for label, w in sorted(high_weight_labels, key=lambda x: x[1], reverse=True):\n",
        "    print(f\"   {label}: {w:.2f}\")\n",
        "print()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-25T22:37:42.843416Z",
          "iopub.execute_input": "2026-01-25T22:37:42.843744Z",
          "iopub.status.idle": "2026-01-25T22:37:42.849692Z",
          "shell.execute_reply.started": "2026-01-25T22:37:42.843717Z",
          "shell.execute_reply": "2026-01-25T22:37:42.849101Z"
        },
        "id": "ctlNIP6cv8Ha",
        "outputId": "62865305-3922-4f59-b3ad-aa810d5d244f"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "\nüìä High-weight labels (will get special threshold tuning):\n   no_sensitivity: 12.00\n\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================\n",
        "# WEIGHT-AWARE THRESHOLD OPTIMIZATION\n",
        "# ======================\n",
        "print(\"üéØ Weight-aware threshold optimization...\\n\")\n",
        "\n",
        "inf_end_time = time.time()\n",
        "tracker.start()\n",
        "preds = trainer.predict(test_tok)\n",
        "probs = 1 / (1 + np.exp(-preds.predictions))\n",
        "y_true = preds.label_ids\n",
        "\n",
        "best_thresholds = []\n",
        "print(\"=\"*80)\n",
        "print(f\"{'Label':<25} {'Thresh':>8} {'F1':>8} {'Prec':>8} {'Rec':>8} {'Supp':>6} {'Wt':>6}\")\n",
        "print(\"-\"*80)\n",
        "\n",
        "for i in range(33):\n",
        "    label_name = LABEL_COLUMNS[i]\n",
        "    support = int(y_true[:, i].sum())\n",
        "    weight = weights[i]\n",
        "\n",
        "    # Strategy based on weight (which reflects training difficulty)\n",
        "    if weight > 10.0:\n",
        "        # Very rare/difficult: aggressive search, favor recall\n",
        "        search_range = np.arange(0.1, 0.8, 0.03)\n",
        "        metric_bias = 'recall'  # Accept lower precision for better recall\n",
        "    elif weight > 5.0:\n",
        "        # Rare: wide search\n",
        "        search_range = np.arange(0.15, 0.85, 0.05)\n",
        "        metric_bias = 'balanced'\n",
        "    else:\n",
        "        # Common: standard search\n",
        "        search_range = np.arange(0.25, 0.75, 0.05)\n",
        "        metric_bias = 'balanced'\n",
        "\n",
        "    best_f1, best_t = 0, 0.5\n",
        "    best_prec, best_rec = 0, 0\n",
        "\n",
        "    for t in search_range:\n",
        "        preds_binary = (probs[:, i] > t).astype(float)\n",
        "        f1 = f1_score(y_true[:, i], preds_binary, zero_division=0)\n",
        "\n",
        "        # For very rare labels, boost recall importance\n",
        "        if metric_bias == 'recall' and support < 30:\n",
        "            rec = recall_score(y_true[:, i], preds_binary, zero_division=0)\n",
        "            # Weighted metric: 70% recall, 30% precision\n",
        "            prec = precision_score(y_true[:, i], preds_binary, zero_division=0)\n",
        "            weighted_f1 = 0.7 * rec + 0.3 * prec\n",
        "            if weighted_f1 > best_f1:\n",
        "                best_f1, best_t = f1, t\n",
        "                best_prec, best_rec = prec, rec\n",
        "        else:\n",
        "            if f1 > best_f1:\n",
        "                best_f1, best_t = f1, t\n",
        "                best_prec = precision_score(y_true[:, i], preds_binary, zero_division=0)\n",
        "                best_rec = recall_score(y_true[:, i], preds_binary, zero_division=0)\n",
        "\n",
        "    best_thresholds.append(best_t)\n",
        "    print(f\"{label_name:<25} {best_t:>8.2f} {best_f1:>8.3f} {best_prec:>8.3f} {best_rec:>8.3f} {support:>6d} {weight:>6.2f}\")\n",
        "\n",
        "inference_emissions = tracker.stop()\n",
        "inf_end_time = time.time()\n",
        "\n",
        "print(\"=\"*80 + \"\\n\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-25T22:38:01.242031Z",
          "iopub.execute_input": "2026-01-25T22:38:01.242356Z",
          "iopub.status.idle": "2026-01-25T22:38:38.308378Z",
          "shell.execute_reply.started": "2026-01-25T22:38:01.242330Z",
          "shell.execute_reply": "2026-01-25T22:38:38.307752Z"
        },
        "id": "1gM-nrKRv8Ha",
        "outputId": "b0d11466-e104-4f87-90e0-9a2c62106959"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "üéØ Weight-aware threshold optimization...\n\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": ""
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "================================================================================\nLabel                       Thresh       F1     Prec      Rec   Supp     Wt\n--------------------------------------------------------------------------------\nacne                          0.70    0.774    0.854    0.707    215   3.00\neye_contour                   0.65    0.889    0.907    0.871    101   3.00\nhomogeneity                   0.65    0.632    0.663    0.604     91   3.00\nlack_firmness                 0.60    0.841    0.832    0.850    193   3.00\nlack_radiance                 0.50    0.784    0.782    0.785    233   3.00\npores                         0.55    0.833    0.861    0.807    207   3.00\nfine_lines                    0.65    0.882    0.861    0.904    335   3.00\nwrinkles_fine-lines           0.70    0.870    0.901    0.840    282   3.00\neye-wrinkles                  0.65    0.835    0.848    0.821    252   3.00\nundereye-bags                 0.60    0.835    0.817    0.853     68   3.00\ngeneric                       0.65    0.575    0.672    0.502    253   3.00\n18-34                         0.65    0.842    0.911    0.783     92   3.00\n35-54                         0.65    0.807    0.819    0.795    210   3.00\n55-99                         0.65    0.793    0.826    0.763     93   3.00\ndark_pigmentation             0.70    0.777    0.820    0.739    111   3.00\ndry                           0.40    0.767    0.703    0.843    197   3.00\nnormal                        0.50    0.671    0.685    0.657    169   3.00\noily                          0.55    0.749    0.778    0.722     97   3.00\ncombination                   0.50    0.670    0.716    0.629    124   3.00\nsensitivity-high              0.65    0.797    0.803    0.792     77   3.00\nsensitivity-low               0.40    0.691    0.646    0.743    113   3.00\nno_sensitivity                0.34    0.231    0.250    0.214     14  12.00\nmale                          0.40    0.898    0.892    0.904     73   3.00\nfemale                        0.70    0.942    0.928    0.957     94   3.00\ncleanse                       0.45    0.758    0.735    0.783     92   3.00\nprepare                       0.25    0.718    0.626    0.843    451   1.99\ntreat                         0.30    0.716    0.651    0.794    282   3.00\ntargeted                      0.60    0.686    0.734    0.644    163   3.00\ncare                          0.40    0.711    0.652    0.781    352   3.00\nmoisturize                    0.50    0.863    0.819    0.912    502   1.60\nprotect                       0.40    0.867    0.793    0.955    177   3.00\nday                           0.50    0.822    0.792    0.855    138   3.00\nnight                         0.65    0.879    0.873    0.885     78   3.00\n================================================================================\n\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================\n",
        "# WEIGHT-THRESHOLD CORRELATION ANALYSIS\n",
        "# ======================\n",
        "print(\"üìä WEIGHT-THRESHOLD ANALYSIS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "analysis_df = pd.DataFrame({\n",
        "    'label': LABEL_COLUMNS,\n",
        "    'weight': weights,\n",
        "    'threshold': best_thresholds,\n",
        "    'support': [int(y_true[:, i].sum()) for i in range(33)]\n",
        "})\n",
        "\n",
        "# Group by weight ranges\n",
        "print(\"\\nAverage thresholds by weight range:\")\n",
        "print(\"-\"*80)\n",
        "analysis_df['weight_range'] = pd.cut(analysis_df['weight'],\n",
        "                                      bins=[0, 3, 5, 10, 20],\n",
        "                                      labels=['Low (0-3)', 'Med (3-5)', 'High (5-10)', 'Very High (10+)'])\n",
        "\n",
        "summary = analysis_df.groupby('weight_range', observed=True)[['threshold', 'support']].agg({\n",
        "    'threshold': ['mean', 'min', 'max'],\n",
        "    'support': 'mean'\n",
        "}).round(3)\n",
        "\n",
        "print(summary)\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üí° INSIGHTS:\")\n",
        "print(f\"   ‚Ä¢ High-weight labels (>5) avg threshold: {analysis_df[analysis_df['weight'] > 5]['threshold'].mean():.3f}\")\n",
        "print(f\"   ‚Ä¢ Low-weight labels (‚â§5) avg threshold: {analysis_df[analysis_df['weight'] <= 5]['threshold'].mean():.3f}\")\n",
        "print(f\"   ‚Ä¢ Labels with threshold < 0.3: {len(analysis_df[analysis_df['threshold'] < 0.3])}\")\n",
        "print(f\"   ‚Ä¢ Labels with threshold > 0.7: {len(analysis_df[analysis_df['threshold'] > 0.7])}\")\n",
        "print(f\"   ‚Ä¢ Threshold range: {analysis_df['threshold'].min():.2f} - {analysis_df['threshold'].max():.2f}\")\n",
        "print(\"=\"*80 + \"\\n\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-25T22:38:54.506819Z",
          "iopub.execute_input": "2026-01-25T22:38:54.507438Z",
          "iopub.status.idle": "2026-01-25T22:38:54.542032Z",
          "shell.execute_reply.started": "2026-01-25T22:38:54.507408Z",
          "shell.execute_reply": "2026-01-25T22:38:54.541434Z"
        },
        "id": "vgq2lG6mv8Ha",
        "outputId": "13e6bf0b-8dc0-406e-db43-9520b0d87dac"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "üìä WEIGHT-THRESHOLD ANALYSIS\n================================================================================\n\nAverage thresholds by weight range:\n--------------------------------------------------------------------------------\n                threshold              support\n                     mean   min   max     mean\nweight_range                                  \nLow (0-3)           0.553  0.25  0.70  184.844\nVery High (10+)     0.340  0.34  0.34   14.000\n\n================================================================================\nüí° INSIGHTS:\n   ‚Ä¢ High-weight labels (>5) avg threshold: 0.340\n   ‚Ä¢ Low-weight labels (‚â§5) avg threshold: 0.553\n   ‚Ä¢ Labels with threshold < 0.3: 1\n   ‚Ä¢ Labels with threshold > 0.7: 0\n   ‚Ä¢ Threshold range: 0.25 - 0.70\n================================================================================\n\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================\n",
        "# FINAL PREDICTIONS\n",
        "# ======================\n",
        "final_preds = np.array([(probs[:, i] > best_thresholds[i]).astype(float) for i in range(33)]).T\n",
        "\n",
        "f1_w = f1_score(y_true, final_preds, average='weighted', zero_division=0)\n",
        "f1_ma = f1_score(y_true, final_preds, average='macro', zero_division=0)\n",
        "f1_mi = f1_score(y_true, final_preds, average='micro', zero_division=0)\n",
        "test_jac = float(jaccard_score(y_true, final_preds, average=\"samples\"))\n",
        "\n",
        "# ======================\n",
        "# MODEL RESULTS\n",
        "# ======================\n",
        "print(\"=\"*80)\n",
        "print(\"üéâ FINAL RESULTS - MODEL\")\n",
        "print(\"=\"*80)\n",
        "print(f\"üéØ Weighted F1: {f1_w*100:.2f}%\")\n",
        "print(f\"üìä Macro F1:    {f1_ma*100:.2f}%\")\n",
        "print(f\"üìà Micro F1:    {f1_mi*100:.2f}%\")\n",
        "print(f\"üìà Jaccard Score:    {test_jac*100:.2f}%\")\n",
        "print(f\"‚è±Ô∏è  Time: {result.metrics['train_runtime']/60:.1f} min\")\n",
        "print(f\"üì¶ Epochs: {EPOCHS}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-25T22:52:00.291009Z",
          "iopub.execute_input": "2026-01-25T22:52:00.291749Z",
          "iopub.status.idle": "2026-01-25T22:52:00.318206Z",
          "shell.execute_reply.started": "2026-01-25T22:52:00.291722Z",
          "shell.execute_reply": "2026-01-25T22:52:00.317612Z"
        },
        "id": "d9l_uhm_v8Ha",
        "outputId": "c71cbc47-9caa-4b71-ce36-a38f153f6e2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "================================================================================\nüéâ FINAL RESULTS - MODEL\n================================================================================\nüéØ Weighted F1: 78.17%\nüìä Macro F1:    76.98%\nüìà Micro F1:    78.21%\nüìà Jaccard Score:    55.79%\n‚è±Ô∏è  Time: 214.0 min\nüì¶ Epochs: 25\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================\n",
        "# SUSTAINABILITY METRICS\n",
        "# ======================\n",
        "co2_per_epoch = training_emissions / EPOCHS\n",
        "co2_per_1k_train = training_emissions / (len(train_df) / 1000)\n",
        "co2_per_f1 = training_emissions / f1_w\n",
        "\n",
        "num_params = sum(p.numel() for p in model.parameters())\n",
        "model_size_mb = num_params * 4 / (1024 ** 2)  # fp32\n",
        "\n",
        "kg_co2_per_min = training_emissions / (result.metrics[\"train_runtime\"] / 60)\n",
        "\n",
        "sustainability_score = (\n",
        "    training_emissions * 0.6 +\n",
        "    inference_emissions * 0.25 +\n",
        "    (1 - f1_w) * 0.15\n",
        ")\n",
        "\n",
        "# ======================\n",
        "# SUSTAINABILITY RESULTS\n",
        "# ======================\n",
        "print(\"=\" * 80)\n",
        "print(\"SUSTAINABILITY REPORT ‚Äî ROBERTA-LARGE\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(f\"Sustainability Score: {sustainability_score:.6f}\")\n",
        "print(f\"Training CO2 (kg): {training_emissions:.6f}\")\n",
        "print(f\"Inference CO2 (kg): {inference_emissions:.6f}\")\n",
        "print(f\"CO2 per epoch (kg): {co2_per_epoch:.6f}\")\n",
        "print(f\"CO2 per 1k training samples (kg): {co2_per_1k_train:.6f}\")\n",
        "print(f\"CO2 per F1 point: {co2_per_f1:.6f}\")\n",
        "print(f\"Emissions per minute (kg): {kg_co2_per_min:.6f}\")\n",
        "\n",
        "print(f\"Model parameters: {num_params:,}\")\n",
        "print(f\"Model size (MB): {model_size_mb:.2f}\")\n",
        "print(\"=\" * 80)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-25T23:08:36.502339Z",
          "iopub.execute_input": "2026-01-25T23:08:36.502962Z",
          "iopub.status.idle": "2026-01-25T23:08:36.511030Z",
          "shell.execute_reply.started": "2026-01-25T23:08:36.502933Z",
          "shell.execute_reply": "2026-01-25T23:08:36.510247Z"
        },
        "id": "01Cgh_YKv8Ha",
        "outputId": "0279d46d-90aa-4d12-ac60-19e4c148e046"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "================================================================================\nSUSTAINABILITY REPORT ‚Äî ROBERTA-LARGE\n================================================================================\nSustainability Score: 0.059806\nTraining CO2 (kg): 0.031781\nInference CO2 (kg): 0.031937\nCO2 per epoch (kg): 0.001271\nCO2 per 1k training samples (kg): 0.005890\nCO2 per F1 point: 0.040659\nEmissions per minute (kg): 0.000148\nModel parameters: 355,393,569\nModel size (MB): 1355.72\n================================================================================\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================\n",
        "# SAVE\n",
        "# ======================\n",
        "print(\"üíæ Saving...\")\n",
        "trainer.save_model(\"./ML_256_EP_25\")\n",
        "tokenizer.save_pretrained(\"./ML_256_EP_25\")\n",
        "np.save(\"best_thresholds_ML_256_EP_25.npy\", best_thresholds)\n",
        "\n",
        "results = pd.DataFrame([{\n",
        "    'weighted_f1': f1_w,\n",
        "    'macro_f1': f1_ma,\n",
        "    'micro_f1': f1_mi,\n",
        "    'epochs': EPOCHS,\n",
        "    'learning_rate': LEARNING_RATE,\n",
        "    'training_minutes': result.metrics['train_runtime']/60\n",
        "}])\n",
        "results.to_csv(\"final_results_ML_256_EP_25.csv\", index=False)\n",
        "print(\"   ‚úÖ All outputs saved\\n\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-25T22:43:08.508501Z",
          "iopub.execute_input": "2026-01-25T22:43:08.509169Z",
          "iopub.status.idle": "2026-01-25T22:43:11.046866Z",
          "shell.execute_reply.started": "2026-01-25T22:43:08.509113Z",
          "shell.execute_reply": "2026-01-25T22:43:11.046274Z"
        },
        "id": "m0BYuV8-v8Hb",
        "outputId": "4ab9b227-15a1-430d-a8ac-059f5de7b346"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "üíæ Saving...\n   ‚úÖ All outputs saved\n\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================\n",
        "# DETAILED REPORT\n",
        "# ======================\n",
        "print(\"=\"*80)\n",
        "print(\"PER-LABEL BREAKDOWN\")\n",
        "print(\"=\"*80)\n",
        "print(f\"{'Label':<25} {'F1':>8} {'Prec':>8} {'Recall':>8} {'Thresh':>8} {'Supp':>6}\")\n",
        "print(\"-\"*80)\n",
        "\n",
        "for i in range(33):\n",
        "    f1 = f1_score(y_true[:, i], final_preds[:, i], zero_division=0)\n",
        "    prec = precision_score(y_true[:, i], final_preds[:, i], zero_division=0)\n",
        "    rec = recall_score(y_true[:, i], final_preds[:, i], zero_division=0)\n",
        "    print(f\"{LABEL_COLUMNS[i]:<25} {f1:>8.3f} {prec:>8.3f} {rec:>8.3f} {best_thresholds[i]:>8.2f} {int(y_true[:, i].sum()):>6d}\")\n",
        "\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "print(f\"\"\"\n",
        "TRAINING SUMMARY:\n",
        "- Full {EPOCHS} epochs completed\n",
        "- Lower learning rate ({LEARNING_RATE}) for fine-tuning\n",
        "- Larger effective batch ({BATCH_SIZE * GRAD_ACCUM})\n",
        "- Advanced threshold optimization (0.5 step size)\n",
        "\n",
        "FINAL F1: {f1_w*100:.2f}%\n",
        "\"\"\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-25T22:42:26.668321Z",
          "iopub.execute_input": "2026-01-25T22:42:26.668895Z",
          "iopub.status.idle": "2026-01-25T22:42:26.848000Z",
          "shell.execute_reply.started": "2026-01-25T22:42:26.668868Z",
          "shell.execute_reply": "2026-01-25T22:42:26.847471Z"
        },
        "id": "NJq1OUwlv8Hb",
        "outputId": "59652042-1ec0-4833-d2b8-df536120c897"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "================================================================================\nPER-LABEL BREAKDOWN\n================================================================================\nLabel                           F1     Prec   Recall   Thresh   Supp\n--------------------------------------------------------------------------------\nacne                         0.774    0.854    0.707     0.70    215\neye_contour                  0.889    0.907    0.871     0.65    101\nhomogeneity                  0.632    0.663    0.604     0.65     91\nlack_firmness                0.841    0.832    0.850     0.60    193\nlack_radiance                0.784    0.782    0.785     0.50    233\npores                        0.833    0.861    0.807     0.55    207\nfine_lines                   0.882    0.861    0.904     0.65    335\nwrinkles_fine-lines          0.870    0.901    0.840     0.70    282\neye-wrinkles                 0.835    0.848    0.821     0.65    252\nundereye-bags                0.835    0.817    0.853     0.60     68\ngeneric                      0.575    0.672    0.502     0.65    253\n18-34                        0.842    0.911    0.783     0.65     92\n35-54                        0.807    0.819    0.795     0.65    210\n55-99                        0.793    0.826    0.763     0.65     93\ndark_pigmentation            0.777    0.820    0.739     0.70    111\ndry                          0.767    0.703    0.843     0.40    197\nnormal                       0.671    0.685    0.657     0.50    169\noily                         0.749    0.778    0.722     0.55     97\ncombination                  0.670    0.716    0.629     0.50    124\nsensitivity-high             0.797    0.803    0.792     0.65     77\nsensitivity-low              0.691    0.646    0.743     0.40    113\nno_sensitivity               0.231    0.250    0.214     0.34     14\nmale                         0.898    0.892    0.904     0.40     73\nfemale                       0.942    0.928    0.957     0.70     94\ncleanse                      0.758    0.735    0.783     0.45     92\nprepare                      0.718    0.626    0.843     0.25    451\ntreat                        0.716    0.651    0.794     0.30    282\ntargeted                     0.686    0.734    0.644     0.60    163\ncare                         0.711    0.652    0.781     0.40    352\nmoisturize                   0.863    0.819    0.912     0.50    502\nprotect                      0.867    0.793    0.955     0.40    177\nday                          0.822    0.792    0.855     0.50    138\nnight                        0.879    0.873    0.885     0.65     78\n================================================================================\n\n\nTRAINING SUMMARY:\n- Full 25 epochs completed\n- Lower learning rate (3e-05) for fine-tuning\n- Larger effective batch (32)\n- Advanced threshold optimization (0.5 step size)\n\nFINAL F1: 78.17%\n\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "w4Gg0DZBv8Hb"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}